![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/616643227_17938211829112832_7387498784522486804_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=102&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=40YcTWqswzYQ7kNvwHa6n_S&_nc_oc=Adn1_dLCt4HRC-V9dDo51dRs8p1ARYTYHh-5OxNBKQN7V-8907WrC7rL4QkvvmKlPKI&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=x6Ig9EcrPJIBWFtUEpLgPA)

## 제목:  
**Meta “Dr. Zero” – 인간 개입 없이 스스로 문제를 만들고 풀어 스스로 진화하는 AI**  

**요약**:  
Meta Superintelligence Labs가 발표한 Dr. Zero는 ‘제안자(Proposer)’와 ‘해결자(Solver)’가 서로 피드백 루프를 형성해 질문을 자동으로 생성·해결한다. 외부 검색 엔진만을 이용해 데이터·주석 없이 학습하며, 기존 지도 학습 기반 검색 에이전트보다 HotpotQA·2WikiMQA 등에서 최대 14.1 % 높은 성능을 기록했다. 핵심은 HRPO(Hop‑Grouped Relative Policy Optimization)라는 효율적인 보상·샘플링 기법이다.  

**쉬운설명**:  
AI가 스스로 “문제 만들기 → 풀기 → 더 어려운 문제 만들기”를 반복합니다. 사람의 도움 없이 웹 검색만으로 학습하고, 질문 난이도를 자동 조정해 가장 효과적인 학습을 진행합니다.  

**관련분야**: AI 자동 커리큘럼 설계, 오픈‑도메인 검색 에이전트, 강화학습  

**중요도**: 10점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTk0TByCLWW  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/616167568_17938168665112832_468790001166538059_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=107&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=TF3TqCkMhJoQ7kNvwEiXkmI&_nc_oc=AdmOIkez6t5kV0tRJofBaQ_fWWgTmVh5YX4jemNhHz36pqgwyZ3hHnxJqRkPEOK9m04&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**Controlled Self‑Evolution (CSE) – 코드 자동 진화를 “통제”한 최신 프레임워크**  

**요약**:  
QuantaAlpha·난징대 연구진은 기존 무작위 코드 진화가 ‘초기화 편향’·‘통제되지 않은 확률적 조작’에 빠지는 문제를 해결하기, ‘다양화된 계획 초기화’, ‘피드백‑기반 유전 진화’, ‘계층적 진화 메모리’를 결합한 CSE를 제안했다. 실험에서 GPT‑5·Claude 4.5·DeepSeek‑V3 백본 모델 모두 CSE 적용 시 실행 시간·메모리 사용량에서 일관된 개선을 보였다.  

**쉬운설명**:  
코드 생성 AI가 처음부터 여러 다른 알고리즘(예: 동적 계획 vs 그리디)으로 시작하고, 컴파일 오류·시간 초과 같은 실제 피드백을 바탕으로 ‘목표 지향적 변이’를 수행합니다. 성공·실패 경험을 기억해 다음 진화에 활용해, 무작위 시도보다 빠르게 좋은 코드를 찾습니다.  

**관련분야**: 자동 코드 생성, 진화 알고리즘, 메타러닝  

**중요도**: 9점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTkrEOPEoPq  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/616404876_17938278438112832_5771082612155684239_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=101&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=LiGfReAz9dIQ7kNvwG9f_wf&_nc_oc=AdnPG6-F0G6RChhjeURHGLYMhy8Nm7XeWGgwIy8yMqKapX_JvzQjgc0OuWc3LVU6l30&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**Cursor 팀, 1 주일 안에 300만 줄 코드로 “완전한 웹 브라우저”를 만든 다중‑AI 에이전트 협업**  

**요약**:  
Cursor는 수백 개의 AI 에이전트를 파이프라인 구조(Planner → Worker → Integrator)로 조직해, GPT‑5.2를 중심으로 1 주일 동안 1 백만 + 줄 코드를 작성, 실제 동작하는 브라우저·엑셀·윈도우 7 에뮬레이터를 완성했다. 역할별 모델 선택이 성능에 크게 기여했으며, 락·병목 문제를 파이프라인 설계로 해결했다.  

**쉬운설명**:  
AI들을 ‘기획자’와 ‘작업자’로 나눠 각각 작은 작업에 집중하게 하면, 수백 명이 동시에 코딩해도 충돌 없이 완성품을 만들 수 있다는 실험 결과다.  

**관련분야**: 다중‑AI 협업, 자동 소프트웨어 개발, AI‑기반 프로젝트 관리  

**중요도**: 8점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTkiHPbipOT  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/617084684_17938192506112832_5093605777900388267_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=102&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=nUYIMCnjCwMQ7kNvwH9Mz8s&_nc_oc=Adl7JNtrQ--ENv28aMkfx3xYDR5PZv3_Zej0EchAePONgyN5CM2FZ4tWNJzT-SRFxy8&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**TongyiLab “ExpSeek” – 웹 에이전트가 스스로 경험을 찾아 활용하도록 하는 프레임워크**  

**요약**:  
ExpSeek은 에이전트 행동·실수·가이드의 삼중항(triplet) 형태로 경험을 기록하고, 필요 시 검색해 재활용한다. Qwen‑3‑8B·32B 모델에 적용해 4가지 웹‑에이전트 벤치마크에서 각각 9.3 %·7.5 % 성능 향상을 달성했다.  

**쉬운설명**:  
AI가 “내가 이렇게 했고, 여기서 실수했으니 다음엔 이렇게 하면 된다”는 작은 메모를 남기고, 비슷한 상황이 오면 바로 꺼내 쓰는 ‘경험 노트’를 갖게 만든다.  

**관련분야**: 웹 자동화 에이전트, 경험 기반 강화학습, 프롬프트 엔지니어링  

**중요도**: 7점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTlHv_skf6h  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/616386127_17938168929112832_7498336582332185305_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=107&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=Z4COtsW65oIQ7kNvwFuGZJU&_nc_oc=Adnq9ZosQzARl9On96_VMo7dVaOR_iQlfHzD8egqS9eQb8e28Vc-6b9eZmPmRWnxJhg&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**MAXS – “선견지명” 전략으로 LLM 에이전트의 근시안적 추론을 해결**  

**요약**:  
MAXS 프레임워크는 미래 시뮬레이션을 통해 여러 단계 앞을 예측하고, 가장 가치 있는 도구·경로만 선택한다. ‘Trajectory Convergence’으로 충분히 확신이 서면 연산을 즉시 중단해 효율성을 높인다. 기존 MCTS보다 가볍고 빠르면서도 성능은 앞선다.  

**쉬운설명**:  
체스에서 몇 수 앞을 내다보듯, AI가 “다음에 어떤 도구를 써야 할까?”를 미리 시뮬레이션하고, 확신이 서면 바로 행동한다. 불필요한 연산을 줄여 빠르고 정확하게 답을 만든다.  

**관련분야**: LLM 에이전트 설계, 탐색 알고리즘, 비용‑효율 최적화  

**중요도**: 6점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTkPoM_EWW9  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/617040851_17938290621112832_6007564776920970259_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=110&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=nHCzDIxN_ykQ7kNvwGr3C0C&_nc_oc=AdmqWwC3R2CbHmLKrGtvxhUI5lDGCqvXFHl6fIEJ0kB66Htjp8CVUbi1C673m9aFEHY&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**StepFun “STEP3‑VL‑10B” – 10 B 파라미터로 Gemini‑2.5 Pro 수준 멀티모달 성능**  

**요약**:  
PaCoRe(Parallel‑Controlled‑Runtime) 기술을 적용해 추론 시 연산 자원을 동적으로 배분, 10 ~ 20 배 더 큰 모델 대비 동일 또는 상위 성능을 달성한다. AIME 2025 벤치마크에서 94.43 %를 기록, 235 B 규모 모델을 앞섰다. Apache 2.0 라이선스로 공개돼 엣지·로컬 멀티모달 AI에 바로 활용 가능.  

**쉬운설명**:  
작은 몸집(10 B 파라미터)에도 큰 몸집(200 B) 수준의 ‘눈·손’ 능력을 주는 특수 엔진을 탑재해, 모바일·산업용 디바이스에서도 고품질 시각·STEM 추론이 가능하게 만든다.  

**관련분야**: 멀티모달 모델, 경량화 추론, 엣지 AI  

**중요도**: 5점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTkGbwpCWFe  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/613570062_17938181001112832_1107846334441323480_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=104&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=zG5aJKL7PoQQ7kNvwGyKOR5&_nc_oc=Adm5-IH9tF82qFtlVkTz4ovFPkbm5FCfDy_hFVZUKljcOZJZ028YELYJeK2m2roTbS4&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**Gemini 2.5 Pro – DeepResearchEval 1위, 연구 리포트 품질을 크게 앞서다**  

**요약**:  
DeepResearchEval 평가에서 Gemini‑2.5‑Pro가 품질 점수 8.51점으로 Claude‑Sonnet‑4.5(7.53)·OpenAI(7.28)를 크게 앞섰다. 특히 ‘통찰력’·‘지시 이행’에서 우수했으며, 팩트 정확도는 Manus가 82.3 %로 1위, Gemini가 76.6 %를 기록했다. 최신 Gemini‑3 Pro 출시를 감안하면, 고품질 리서치·보고서 작성을 위한 최우선 선택으로 부상한다.  

**쉬운설명**:  
AI가 논문·리포트 작성 시 ‘어디서 찾은 정보가 신뢰할까’, ‘요구사항을 정확히 따라줄까’를 평가했을 때, Gemini 2.5 Pro가 가장 좋은 점수를 받았다.  

**관련분야**: AI‑기반 연구·리포팅, LLM 평가 벤치마크, 생성형 AI 품질 관리  

**중요도**: 4점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTkYzQXkVy9  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.71878-15/613831391_866505739456422_7583737990432418705_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=108&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=wawQdAmdM6EQ7kNvwEiX_g7&_nc_oc=Adn1m8tCozZRcqEoRZ7ZGvPp5VkP3mT4IQHdF7DmYbrCCaJc-j_jfHkq8TpwN3Sl79U&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목:  
**Soprano TTS – 80 M 파라미터, CPU에서도 실시간 2000배 빠른 초경량 텍스트‑투‑스피치**  

**요약**:  
새로운 로컬 TTS 엔진 Soprano는 1 GB 미만 크기의 80 M 파라미터 모델로, GPU 기반 실시간보다 2000 배 빠른 속도를 제공한다. 1.1 버전에서 환각 현상을 감소시키고 파인튜닝 코드를 공개했으며, 현재는 영어 전용이지만 오픈소스이기에 곧 한국어 모델이 등장할 전망이다.  

**쉬운설명**:  
작은 파일 크기와 CPU만으로도 거의 지연 없이 말소리를 만들 수 있는 ‘초소형 TTS’. 모바일·IoT·오프라인 환경에 바로 적용 가능하다.  

**관련분야**: 텍스트‑투‑스피치, 경량 AI, 온‑디바이스 음성 합성  

**중요도**: 3점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTlcQNIDcte  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/17984981615941928_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=ghvPIL_xQloQ7kNvwF3EKpN&_nc_oc=AdnPlvxXXgBcvGZn8bIv8PiY0VKP8e6pRqWJO2oVOi4aZOAN4h3u7Fy7eGOlBth9-ME&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목:  
**OpenResponses – LLM 인터페이스를 위한 오픈소스 표준 API**  

**요약**:  
OpenAI·Vercel·NVIDIA·Hugging Face가 공동으로 ‘Open Responses’ 스키마를 발표, 모델 공급자마다 달랐던 API 차이를 하나의 표준으로 통합한다. 기존 OpenAI API를 기반으로 하면서도 공급자 종속성을 없애, 모델 교체 시 코드 수정 부담을 크게 감소시킨다.  

**쉬운설명**:  
‘전기 콘센트가 다 다르던 시절’에 ‘전 세계가 쓰는 동일 플러그’를 만든 것과 같다. 어느 LLM을 쓰든 동일한 코드로 호출할 수 있게 된다.  

**관련분야**: LLM 인프라, API 표준화, AI 모델 배포  

**중요도**: 2점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTjlV3gAq5g  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/617727670_17938386123112832_8326219608562528355_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=105&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=X_Oq14v1LjIQ7kNvwF0notu&_nc_oc=AdlyvEQNGvUiY_3uwDjQlWUYPq8KmoFRs1TGVEboXU9DpNpG8BBxJcOooi_K-rihSnA&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목:  
**일론 머스크, 2017년 오픈AI 비영리‑영리 전환 논의 메모 공개**  

**요약**:  
일론 머스크가 2017년 오픈AI의 비영리 구조를 B‑Corp 혹은 C‑Corp 형태의 영리 조직으로 바꾸자는 의견을 제시한 통화 메모가 공개됐다. 머스크는 최근 법정 서류에서 “본질적으로 자선적인 활동(essentially philanthropic endeavor)”이라 주장하지만, 실제 논의는 영리 전환 가능성을 탐색한 것으로 보인다.  

**쉬운설명**:  
오픈AI가 ‘비영리’에서 ‘영리 기업’으로 바뀔 수 있는 길을 머스크가 미리 고민했으며, 그 기록이 이제 공개된 상황이다.  

**관련분야**: AI 거버넌스·법률, 기업 조직 형태, 인공지능 정책  

**중요도**: 1점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTliMlSk5VO  