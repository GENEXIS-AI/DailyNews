![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/608848652_17937096099112832_3819370636135805438_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=103&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWg)

## 제목: MiroThinker 1.5 – “Interactive Scaling”으로 검색·추론 능력 혁신  
**요약**: 오픈소스 프로젝트 MiroThinker 1.5는 Qwen‑3 기반 모델에 ‘상호작용 스케일링(Interactive Scaling)’을 적용해 모델 크기를 늘리지 않고도 최대 600번의 도구 호출을 수행한다. 256K 토큰 컨텍스트를 처리하며 복잡한 리서치 작업에서 폐쇄형 상용 모델을 능가한다.  
**쉬운설명**: 모델이 큰 만큼이 아니라, 질문에 대해 여러 번 “도구를 쓰면서” 답을 찾아가는 방식으로 성능을 높였어요. 즉, 한 번에 많은 정보를 찾고 검증하는 인간 연구자의 행동을 모방한 겁니다.  
**관련분야**: 대형 언어모델(Large Language Model), 도구 활용(Tool‑augmented LLM), 검색‑증강 추론(Retrieval‑augmented Generation)  
**중요도**: 10점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTJEHaZjVWd  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t16/f2/m84/AQP3S_dCZMiebQ24h_jTB9ObNmjtJn7Bf-TYRV72FPVoxp3Uesed2bM5MDZMhE3cRPlPIjCjJBzxEBFbbcPuzjccwqoWGXtIHqRRI-g.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLmZlZWQudW5rbm93bi1DMy44NTIuZGFzaF9iYXNlbGluZV8xX3YxIn0&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목: DualityForge – 영상 환각(Hallucination) 감소를 위한 새로운 데이터·학습 파이프라인  
**요약**: 알리바바 AMAP‑ML팀은 ‘DualityForge’라는 데이터셋과 ‘DNA‑Train’ 강화학습을 통해 영상‑언어 멀티모달 모델이 시각 정보를 무시하고 언어적 상식에 의존해 오류를 내는 현상을 24 % 감소시켰다. Qwen2.5‑VL‑7B 대비 크게 개선된 성능을 보였다.  
**쉬운설명**: 원본 영상과 고의로 물리 법칙을 깨는 변형 영상을 쌍으로 학습시켜, 모델이 ‘보는 것’ 자체에 집중하도록 만든 거예요. 그래서 화면에 없는 상식을 떠올리는 오류가 줄어듭니다.  
**관련분야**: 멀티모달 대형 모델(Multi‑modal LLM), 비디오‑텍스트 정합성, 모델 환각 방지  
**중요도**: 9점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTI5zZZjnmh  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/610955441_17937104043112832_4700053946634558787_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=110&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=iK_TsQkxlFsQ7kNvwGLf5r7&_nc_oc=Adm67OX_DMsCxpq0YYiRe12UQHsyqNqn6San1_K4mVqFa9RYH21Nu4GS7b2o2c3Gz3U)

## 제목: ALE‑Agent – 인간 전문가 800명을 제치고 AtCoder Heuristic Contest 058 우승  
**요약**: 일본 Sakana AI가 만든 ALE‑Agent는 4 시간 내 4,700회 이상의 LLM 호출(GPT‑5.2·Gemini 3 Pro)로 코드를 자동 생성·실행해 최적화 문제를 해결했다. 가상 전력 휴리스틱과 대규모 이웃 탐색(Large Neighborhood Search) 등 독창적인 알고리즘으로 800명 인간 참가자를 앞섰다.  
**쉬운설명**: AI가 짧은 시간 안에 수천 번 코드를 짜고 실행해, 사람처럼 ‘시도‑실패‑교정’ 과정을 스스로 반복하며 최적의 해를 찾은 겁니다.  
**관련분야**: 자동 프로그래밍(Program Synthesis), 휴리스틱 최적화, 실시간 코드 생성  
**중요도**: 8점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTInaJtjxG7  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/607780727_17937098040112832_8887358118903963323_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=105&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=yh8x-vdbZwoQ7kNvwEQqf7s&_nc_oc=AdmMwexg70AHFsXffDIvPAlbwBsccKBUg6UJtnJRA9cCG73zfpnrU3zTsebzPRPDAzU)

## 제목: Falcon H1R‑7B – 7B 파라미터에 256K 컨텍스트와 뛰어난 수학·코딩 성능  
**요약**: TII가 발표한 Falcon H1R‑7B는 Mamba와 Transformer를 결합한 하이브리드 구조로, 7 B 파라미터 모델임에도 256 K 토큰 컨텍스트와 수학·코딩 벤치마크에서 경쟁 모델을 앞선다. 일반 노트북(RTX 5060급)에서도 실시간 추론이 가능하다.  
**쉬운설명**: 작은 모델이지만 긴 글을 한 번에 읽고, 복잡한 수학 문제까지 풀 수 있게 만든 ‘새로운 엔진’이라고 보면 됩니다.  
**관련분야**: 경량 대형 언어모델, 하이브리드 아키텍처, 고컨텍스트 처리  
**중요도**: 7점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTIlPFkE7Jy  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610877271_17937053913112832_705572054181925132_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=HVh3W2KXHX8Q7kNvwHGGLXP&_nc_oc=AdlcJ59E99yCiFXrnfGlIaem0Y92zy0lOQ8flyl5ylJWuznCA90YNiFqp4_QpIdHKAo&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목: SenseNova‑MARS – 8B 파라미터 VLM이 GPT‑5·Gemini‑3‑Flash를 능가  
**요약**: SenseTime의 SenseNova‑MARS는 이미지 크롭·텍스트·이미지 서치가 결합된 에이전트형 VLM이다. BN‑GSPO 강화학습으로 학습 안정성을 높였으며, 4K 이미지 처리 벤치마크 HR‑MMSearch에서 GPT‑5·Gemini‑3‑Flash보다 높은 성능을 기록했다.  
**쉬운설명**: 모델이 이미지의 중요한 부분을 돋보듯 확대하고, 부족한 정보를 실시간 검색해 ‘보고 생각하는’ 방식을 흉내냈습니다.  
**관련분야**: 비전‑언어 모델(VLM), 멀티모달 추론, 강화학습  
**중요도**: 6점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTIQqbhgSew  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610759097_17937075810112832_523150004468059707_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=103&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=HdGnhUilyb0Q7kNvwFQ5q2Z&_nc_oc=AdmNZ_D_XvlfmZlVhjlvCF8c0M8jdColXMbVHU1BZY8AI4IcZxFaMpx1KHOO8SWT1FE&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목: 딥마인드·구글 “Nested Learning(NL)” – 지속학습의 새로운 패러다임  
**요약**: 구글 연구진은 “중첩 학습(Nested Learning)”을 제안해 모델을 서로 다른 학습 속도와 최적화 문제를 겹쳐 가진 시스템으로 재정의한다. 다중 스케일 모멘텀(M3)·연속체 기억 시스템(CMS) 등을 도입해 파국적 망각을 방지하고 10 M 토큰 길이 장문 이해에서 기존 트랜스포머를 크게 앞섰다.  
**쉬운설명**: 모델을 하나의 층이 아니라, 여러 ‘학습 모듈’이 동시에 독립적으로 진화하는 구조로 바꿔서, 계속 새로운 지식을 습득하면서도 기존 지식을 잃지 않게 만든 기술이에요.  
**관련분야**: 지속학습(Continual Learning), 최적화 이론, 메타‑학습  
**중요도**: 5점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTIGV60iIGN  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610752007_17937053766112832_8251120771415206689_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=105&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=5g67b2edSAYQ7kNvwHz7FU_&_nc_oc=AdniuigjXfQRhlwD60D-XDOR8dQr66qLEvhxDinUDHeoYaz1IG3pSGsJglIV1bHW4Cw)

## 제목: Youtu‑Agent – 도구·프롬프트 자동 생성 오픈소스 에이전트 프레임워크  
**요약**: 텐센트는 Youtu‑Agent를 공개했다. ‘Workflow Mode’와 ‘Meta‑Agent Mode’가 사용자의 요구를 분석해 필요한 도구와 프롬프트를 자동 생성하고, 81 % 도구 합성 성공률을 달성한다. Agent Practice와 Agent RL 모듈로 파라미터 업데이트 없이도 경험 축적·대규모 강화학습이 가능하며, WebWalkerQA 71.47 %·GAIA 72.8 % 성능을 기록했다.  
**쉬운설명**: AI가 “무엇을 해야 할까?”를 스스로 판단하고, 필요한 프로그램 코드를 만들고, 그걸 실행해 배우는 ‘자율 개발자’ 같은 시스템입니다.  
**관련분야**: 에이전트 기반 자동화, 도구 사용 언어 모델(Tool‑augmented LLM), 오픈소스 AI 인프라  
**중요도**: 4점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTH8C0dgnJ7  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610709223_17937053511112832_3191980450033509255_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=Enh2bn9IkAsQ7kNvwHCkA45&_nc_oc=Admiv3ZlRaE1vwxxf8wYsD5jDsGxgbSMItBgBfvMF1ZpUiayGOCV-mGW6_OfSbZB7KI&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목: Fast‑weight Product Key Memory (FwPKM) – 장기·단기 기억을 동시에 갖춘 새로운 메모리 구조  
**요약**: Llion Jones와 Sakana AI 연구팀은 FwPKM을 제안, 기존 정적인 PKM을 추론 단계에서도 파라미터를 업데이트하는 ‘Fast‑weight’ 방식으로 변형했다. 4 K 토큰 훈련에도 128 K 토큰 테스트에서 안정적인 검색 성능을 보이며, 반복 암기(Iterative Memorization)로 정확도가 크게 상승한다.  
**쉬운설명**: 모델이 대화 도중 새로운 정보를 바로 기억하고 꺼낼 수 있게 만든 ‘실시간 기억 장치’입니다. 그래서 짧은 훈련에도 긴 텍스트를 잘 이해합니다.  
**관련분야**: 기억‑증강 언어모델, Fast‑weight 메모리, 대규모 토큰 처리  
**중요도**: 3점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTHxsonjCfw  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t16/f2/m84/AQO7BpjdmyYD9_5cAhpz1DGoQbPzYoRVkaKS81vmCwEZ776fEq-RC0x74wKuKqibFhf3uzoLERida84lnwtHyK_Bxttd4YZ_VI4rfyk.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLmZlZWQudW5rbm93bi1DMy4xMjgwLmRhc2hfYmFzZWxpbmVfMV92MSJ9&_nc_ht=scontent-iad3-1.cdninstagram.com)

## 제목: Avatar Forcing – 인과적 생성으로 실시간 AI 아바타 인터랙션 구현  
**요약**: KAIST 연구팀은 ‘Avatar Forcing’ 기술을 발표, 사용자 목소리·표정을 실시간 분석해 즉시 반응하는 AI 아바타를 만들었다. 인과적(Causal) 생성 방식으로 지연을 최소화하고 DPO를 적용해 ‘고정된’ 현상을 해소, 활발한 경청 행동을 구현한다.  
**쉬운설명**: AI가 사람의 말을 듣고 바로 고개를 끄덕이거나 표정을 바꾸는 등, 실시간 대화를 자연스럽게 이어주는 가상 인간을 만든 셈입니다.  
**관련분야**: 실시간 멀티모달 인터페이스, 인과적 생성 모델, 인간‑AI 상호작용(Human‑AI Interaction)  
**중요도**: 2점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTHnd1ejCXw  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/611284252_17937050370112832_3975006985985316957_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=106&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=uqzIOGVwEtkQ7kNvwGHyn0i&_nc_oc=AdmMPZ0hhS-grUXdNpJaFgSVT1lbXsI_sLKDvw3z-pAIJ28YwnXjv53u_qLScI3zdaA&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com)

## 제목: Kanana‑v‑4b‑Hybrid – 한국어 제약 조건을 그대로 처리하는 하이브리드 멀티모달 모델  
**요약**: 카카오는 Kanana‑v‑4b‑Hybrid을 공개했다. 4 B 파라미터 모델이 복합 제약 조건(예: “~만 제외하고”)을 한국어 그대로 이해하고, 시각적 추론·자기 점검 능력을 결합해 KoNET에서 92.8점, 과학·공학·문서 이해 벤치마크에서도 글로벌 대형 모델을 근접한다.  
**쉬운설명**: 한국어를 번역 없이 직접 사고하고, 이미지·텍스트를 동시에 다룰 수 있는 ‘스위스 군용 나이프’ 같은 모델이에요.  
**관련분야**: 한국어 특화 대형 모델, 멀티모달 언어 모델, 하이브리드 추론 구조  
**중요도**: 1점  
**전체링크** :  https://www.threads.net/@choi.openai/post/DTHdMWmCD3h