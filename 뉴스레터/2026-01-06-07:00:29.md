![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/608848652_17937096099112832_3819370636135805438_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=103&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=XDlz9HyNq0YQ7kNvwGqoX4g&_nc_oc=AdnjMfXv9ud5Sxy6ScoAPfFciH_UTj30FkgMUxauiH0Kcz-FevSIodyGJivn6f4J1GM&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfoNpdqH1RkUK9LFOrcdirluWPuBASqyhWMgwnR8WGAqdQ&oe=69621A8C)  

## 제목:  
**MiroThinker 1.5 – “상호작용 스케일링”으로 폐쇄형 모델을 뛰어넘다**  

**요약**:  
오픈소스 프로젝트 MiroThinker 1.5는 Qwen‑3 기반에 “상호작용 스케일링(Interactive Scaling)”을 적용해 모델 크기를 늘리지 않고도 600 회의 도구 호출(Tool calls)까지 수행한다. 256K 문맥을 처리하며 복잡한 리서치 작업에서 기존 폐쇄형 모델들을 앞선다.  

**쉬운설명**:  
전통적인 방법은 모델을 더 크게 만들면 성능이 올라간다고 생각하지만, MiroThinker 1.5는 ‘생각을 여러 번 반복하고 검증하는’ 과정을 600번이나 수행해 스스로 정보를 찾고 확인한다. 즉, “깊게 생각하는” 능력을 키운 것이다.  

**관련분야**: 자연어 처리·대규모 언어모델·AI 연구·오픈소스 AI  

**중요도**: 10점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTJEHaZjVWd  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.71878-15/587492964_1815177845853179_5906436890482836447_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=G6rdro4Kpu4Q7kNvwHKU1sd&_nc_oc=Admvs7O3c1KcV3t9WORsz7dLyGMj0Mgm28yJH8DfDGlOqnrKXJ9prV889U7uKYXc2jA&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfpKhP5V6D46F49GgpLQHBKE8ZbXavZ0ucbuJscch9hIDw&oe=69621CA5)  

## 제목:  
**DualityForge – 영상 ‘환각(Hallucination)’을 24 % 줄인 새로운 MLLM 학습법**  

**요약**:  
알리바바 AMAP‑ML팀은 원본 영상과 상식을 깨는 변형 영상을 쌍으로 만든 “DualityForge”와 특수 강화학습 “DNA‑Train”을 제안했다. Qwen2.5‑VL‑7B 대비 영상 환각을 24 % 감소시키고, 벤치마크에서도 성능 향상을 달성했다.  

**쉬운설명**:  
AI가 영상을 보고 “이건 물리법칙에 어긋나는데도 답을 만든다”는 오류를 ‘환각’이라고 한다. DualityForge는 올바른 영상과 의도적으로 틀린 영상을 같이 학습시켜, 모델이 실제 시각 정보에만 의존하도록 만든다.  

**관련분야**: 멀티모달 학습·비전‑언어 모델·AI 안정성·영상 이해  

**중요도**: 9점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTI5zZZjnmh  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.71878-15/609075284_874569285271964_1469463756727802544_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=107&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=pC_FejBwnMQQ7kNvwH--R_G&_nc_oc=AdmNgld6x9L4qnvU6aw58S_wu8MK8cC9XP3QexjvRJJPNeCUJ0Cc6PxZVpf-H46EaCI&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfpDotbG6AjNo1hpPjAfM2oHfKVUPfyWyJB2EbxYKUEtrA&oe=69621412)  

## 제목:  
**LG CLOiD – 가정용 로봇이 ‘피지컬 AI’로 집안일을 수행**  

**요약**:  
LG전자는 CES 2026에서 7관절 팔과 5손가락을 가진 가정용 로봇 “LG CLOiD”를 공개했다. VLM + VLA 기반 피지컬 AI가 수만 시간의 가사 데이터를 학습해 아침 식사 준비, 빨래 개기, 식기 정리 등 복합 작업을 수행한다.  

**쉬운설명**:  
‘피지컬 AI’는 시각(눈)과 행동(손)을 동시에 제어하는 기술이다. CLOiD는 사람처럼 물건을 잡고 움직이며, 사전에 모은 가사 데이터를 바탕으로 “어떻게 하면 가장 효율적인가”를 스스로 판단한다.  

**관련분야**: 로보틱스·휴머노이드 로봇·인공지능·스마트 홈  

**중요도**: 8점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTIvNQ8iYSZ  

---  

![Image](https://scontent-iad3-1.cdninstagram.com/v/t51.82787-15/610955441_17937104043112832_4700053946634558787_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=110&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=iK_TsQkxlFsQ7kNvwGLf5r7&_nc_oc=Adm67OX_DMsCxpq0YYiRe12UQHsyqNqn6San1_K4mVqFa9RYH21Nu4GS7b2o2c3Gz3U&_nc_zt=23&_nc_ht=scontent-iad3-1.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfqwHjPZR1Dt543Z2ooLUjW5K2yd19Fmq4EK94LonCQbfQ&oe=696200DA)  

## 제목:  
**ALE‑Agent – AI가 알고리즘 경진대회에서 인간 800명을 제치고 1위**  

**요약**:  
일본 Sakana AI의 ALE‑Agent가 AtCoder Heuristic Contest 058에서 4시간 내 4,700 번 이상의 LLM 호출을 통해 최적화 알고리즘을 자동 생성·검증, 인간 전문가 800명을 앞서 1위를 차지했다.  

**쉬운설명**:  
ALE‑Agent는 “코드 생성 → 실행 → 결과 분석 → 개선”을 반복하는 ‘추론‑시간 스케일링’을 활용한다. 가상 전력 평가와 대규모 이웃 탐색(Large Neighborhood Search) 같은 독창적인 휴리스틱을 스스로 발견해, 짧은 시간에 인간 수준의 최적화 전략을 만든다.  

**관련분야**: 자동 프로그래밍·메타‑학습·알고리즘 설계·AI 경진대회  

**중요도**: 7점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTInaJtjxG7  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/607780727_17937098040112832_8887358118903963323_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=105&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=yh8x-vdbZwoQ7kNvwEQqf7s&_nc_oc=AdmMwexg70AHFsXffDIvPAlbwBsccKBUg6UJtnJRA9cCG73zfpnrU3zTsebzPRPDAzU&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfoCxLHZjJ6QfvVeA1l28ce-OpIEVA1DJ5f9KBJCsFHIFA&oe=69621C13)  

## 제목:  
**Falcon H1R‑7B – 7 B 파라미터에 256K 문맥과 뛰어난 수학·코딩 능력**  

**요약**:  
TII가 발표한 Falcon H1R‑7B는 Mamba와 Transformer를 혼합한 하이브리드 아키텍처로, 7 B 규모이지만 256K 문맥 길이와 수학·코딩 벤치마크에서 기존 대형 모델을 앞선다. 일반 RTX 5060급 노트북에서도 실시간 추론이 가능하다.  

**쉬운설명**:  
‘Mamba + Transformer’는 빠른 상태 전이와 장기 기억을 동시에 제공한다. 결과적으로 작은 모델이지만 매우 긴 텍스트를 이해하고 복잡한 수학·프로그래밍 문제를 풀 수 있다.  

**관련분야**: 경량 LLM·효율적인 트랜스포머·코드 생성·수학 추론  

**중요도**: 6점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTIlPFkE7Jy  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610877271_17937053913112832_705572054181925132_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=HVh3W2KXHX8Q7kNvwHGGLXP&_nc_oc=AdlcJ59E99yCiFXrnfGlIaem0Y92zy0lOQ8flyl5ylJWuznCA90YNiFqp4_QpIdHKAo&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfqgBz9XcUUCPouzbUj4dXQJF0Gb0aj00C3Cq6E1OTvbkQ&oe=69620689)  

## 제목:  
**SenseNova‑MARS – 8 B 파라미터 VLM이 ‘돋보기’ 방식으로 이미지·텍스트를 결합**  

**요약**:  
SenseTime의 SenseNova‑MARS는 이미지 크롭·텍스트·이미지 서치를 연계한 에이전트형 VLM으로, 8 B 파라미터만으로 GPT‑5·Gemini‑3‑Flash를 능가한다. BN‑GSPO 강화학습으로 학습 안정성을 높였으며, HR‑MMSearch 벤치마크에서 최고 성능을 기록했다.  

**쉬운설명**:  
모델이 고해상도 사진을 볼 때, 중요한 부분을 확대(‘돋보기’)해서 자세히 본 뒤, 필요하면 텍스트 검색을 통해 부족한 정보를 실시간으로 보충한다. 이렇게 ‘보고 생각하고 찾는’ 순환이 인간의 시각‑인지 과정을 모방한다.  

**관련분야**: 비전‑언어 모델·멀티모달 추론·강화학습·이미지 검색  

**중요도**: 5점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTIQqbhgSew  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610759097_17937075810112832_523150004468059707_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=103&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=HdGnhUilyb0Q7kNvwFQ5q2Z&_nc_oc=AdmNZ_D_XvlfmZlVhjlvCF8c0M8jdColXMbVHU1BZY8AI4IcZxFaMpx1KHOO8SWT1FE&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_Afr2qWSl5fG16SpR2Fmt9tsR6nARs8KQGuTShng2Z0NvFw&oe=6962018C)  

## 제목:  
**Nested Learning – AI 지속학습을 위한 새로운 ‘중첩 최적화’ 패러다임**  

**요약**:  
Google Research가 제안한 ‘Nested Learning(NL)’은 모델을 여러 독립적인 최적화 문제의 집합으로 바라본다. 각 서브모듈이 서로 다른 시간 척도와 업데이트 빈도로 학습해, 연속체 기억 시스템(CMS)으로 파국적 망각을 방지한다. HOPE 모델은 이 방식을 적용해 1천만 토큰 장문 이해와 지속학습 과제에서 기존 트랜스포머·RNN을 능가했다.  

**쉬운설명**:  
전통적인 딥러닝은 “층을 쌓는 것”에 초점을 맞췄지만, NL은 “여러 개의 작은 학습 엔진이 서로 다른 속도로 동시에 움직이는” 구조다. 고주파 엔진은 최신 정보를 빠르게 받아들이고, 저주파 엔진은 중요한 지식을 오래 보존한다.  

**관련분야**: 지속학습·멀티스케일 최적화·신경망 메모리·AI 기초연구  

**중요도**: 4점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTIGV60iIGN  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610752007_17937053766112832_8251120771415206689_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=105&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=5g67b2edSAYQ7kNvwHz7FU_&_nc_oc=AdniuigjXfQRhlwD60D-XDOR8dQr66qLEvhxDinUDHeoYaz1IG3pSGsJglIV1bHW4Cw&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_Afo_DTDO8_8P7KEzMTxjR5j-PC3YBLSzCeK8Ve6tN9L4Kg&oe=69621221)  

## 제목:  
**Youtu‑Agent – 자동 도구·프롬프트 생성으로 에이전트 구축 비용 80 % 절감**  

**요약**:  
텐센트는 오픈소스 에이전트 “Youtu‑Agent”를 공개했다. “Workflow Mode”와 “Meta‑Agent Mode”를 통해 사용자의 요구를 분석하고, 필요한 도구와 프롬프트를 자동으로 생성한다. 도구 합성 성공률 81 %와 WebWalkerQA 71.47 %·GAIA 72.8 % 점수로 상용 모델 수준을 입증했다.  

**쉬운설명**:  
전통적인 에이전트는 개발자가 직접 툴‑연결 코드를 쓰고 프롬프트를 설계해야 했다. Youtu‑Agent는 사용자의 목표를 이해하면, “이런 툴이 필요해”라 판단하고 해당 툴 코드를 자동으로 만들고 연결한다. 따라서 개발 시간과 비용이 크게 감소한다.  

**관련분야**: 자동화 AI 에이전트·프롬프트 엔지니어링·오픈소스 ML·툴‑통합  

**중요도**: 3점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTH8C0dgnJ7  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.82787-15/610709223_17937053511112832_3191980450033509255_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=111&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=Enh2bn9IkAsQ7kNvwHCkA45&_nc_oc=Admiv3ZlRaE1vwxxf8wYsD5jDsGxgbSMItBgBfvMF1ZpUiayGOCV-mGW6_OfSbZB7KI&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfpC2eiRMdr3Oasx49LWNIjZgZr5Fz0DdvoKekuIpBlSyA&oe=69621852)  

## 제목:  
**Fast‑weight Product Key Memory (FwPKM) – 추론 단계에서도 ‘학습’하는 새로운 기억 메커니즘**  

**요약**:  
Ll​ion Jones와 Sakana AI 팀은 FwPKM을 발표했다. 기존 정적인 PKM을 ‘Fast‑weight’ 기법으로 확장해, 추론 시에도 파라미터를 실시간 업데이트한다. 4 K 문맥으로 훈련했지만 128 K 문맥에서도 높은 정확도를 유지하고, 반복 읽기 시 기억 정확도가 크게 상승한다.  

**쉬운설명**:  
보통 모델은 학습 단계에서만 기억을 만들고, 추론 단계에서는 고정된다. FwPKM은 대화 중에 새로운 정보를 바로 저장하고 꺼낼 수 있게 하여, 인간이 “방금 들은 이야기를 바로 기억하는” 것과 비슷한 일화적 기억(Episodic Memory)을 제공한다.  

**관련분야**: 메모리‑증강 모델·대규모 언어 모델·연속 학습·인공 신경망 구조  

**중요도**: 2점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTHxsonjCfw  

---  

![Image](https://scontent-iad3-2.cdninstagram.com/v/t51.71878-15/610261464_730433516382310_2005932150951879825_n.jpg?stp=dst-jpg_e35_tt6&_nc_cat=106&ccb=7-5&_nc_sid=18de74&efg=eyJlZmdfdGFnIjoiRkVFRC5iZXN0X2ltYWdlX3VybGdlbi5DMyJ9&_nc_ohc=olgcQd7seRcQ7kNvwFFONs3&_nc_oc=Adl3t33lNXP0mYUpTjU0CB73cpQ_TVzoTlhLxFLdI6av143i3POfmiD08WpxOMJ2RIw&_nc_zt=23&_nc_ht=scontent-iad3-2.cdninstagram.com&edm=ACx9VUEEAAAA&_nc_gid=QCtO5AibzE3vEXrl8WsmIw&oh=00_AfqUbKBhODx0EtmpWAN1ZKftcQTADvs80VbCOMkTcMAG_A&oe=69621BBD)  

## 제목:  
**Avatar Forcing – 실시간 표정·음성 반응을 구현한 AI 아바타**  

**요약**:  
KAIST 연구팀은 인과적 생성(Causal Generation)과 DPO 기반 학습을 결합해, 사용자의 음성·표정을 실시간으로 분석하고 즉시 반응하는 AI 아바타 “Avatar Forcing”을 발표했다. 지연 시간을 크게 줄이고, 고개 끄덕임·표정 모방 등 ‘적극적 경청’을 구현했다.  

**쉬운설명**:  
기존 모델은 미래 프레임까지 미리 계산해 지연이 커졌다. Avatar Forcing은 현재 입력만으로 즉시 반응하도록 설계돼, 사람과 대화할 때 “맞장구치고” 눈맞춤을 유지한다.  

**관련분야**: 실시간 대화형 AI·가상 인간·멀티모달 인터페이스·인간‑컴퓨터 상호작용  

**중요도**: 1점  

**전체링크** :  https://www.threads.net/@choi.openai/post/DTHnd1ejCXw  