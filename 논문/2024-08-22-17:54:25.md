![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11318.png)
## 제목: TWLV-I: Analysis and Insights from Holistic Evaluation on Video Foundation Models
**요약**:  
이 논문에서는 비디오 기초 모델을 공정하고 강건하게 평가하는 방법을 논의합니다. 언어 모델이나 이미지 모델과 달리 비디오 기초 모델은 샘플링 속도, 프레임 수, 사전 훈련 단계 등 다양한 매개변수로 평가되고 있기 때문에 공정한 비교가 어렵습니다. 이 논문에서는 비디오 이해의 두 가지 핵심 역량, 즉 **appearance**(외형 이해)와 **motion**(모션 이해)을 측정하기 위한 평가 프레임워크를 제시합니다. 기존 모델들은 이 두 가지 역량 중 적어도 하나에 한계를 드러내고 있습니다. 이를 극복하기 위해 TWLV-I라는 새로운 비디오 기초 모델을 소개하며, 이는 모션 및 외형 기반 비디오 모두에 대한 강건한 시각적 표현을 구성합니다.

본 모델은 다섯 개의 행동 인식 기준에서 선형 프로빙의 평균 top-1 정확도에서 V-JEPA (ViT-L)에 비해 4.6%p, UMT (ViT-L)에 비해 7.7%p 개선된 성능을 보였습니다. 더 큰 모델들에 비해서도 DFN(ViT-H)와 7.2%p, V-JEPA(ViT-H)와 2.7%p, InternVideo2(ViT-g)와 2.8%p 개선된 결과를 나타냈습니다. 연구에서 사용된 비디오 벤치마크의 임베딩 벡터와 이 임베딩을 직접 활용할 수 있는 평가 소스 코드도 제공됩니다. 

**쉬운설명**:  
이 논문은 비디오를 잘 이해하는 모델을 평가하는 방법을 설명합니다. 비디오 모델은 다른 모델들과 비교할 때 여러 가지 방식을 사용하기 때문에 공정한 비교가 힘듭니다. 저자들은 비디오의 겉모습과 움직임을 이해하는 두 가지 중요한 능력을 측정하는 새로운 방법을 제안합니다. 기존 모델들이 이 두 가지 능력 중 하나에서 잘 작동하지 않는 것을 발견하고, TWLV-I라는 더 나은 모델을 만들어 이 문제를 해결했습니다. 이 모델은 다양한 평가에서 더 나은 성능을 보였으며, 관련된 데이터와 코드도 공개하였습니다.

**관련분야**: 영상 이해, 머신 러닝, 컴퓨터 비전  
**추천수**: 23  
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2408.11318)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11796.png)
## 제목: LLM Pruning and Distillation in Practice: The Minitron Approach
**요약**:  
이 논문은 Llama 3.1 8B 및 Mistral NeMo 12B 모델을 각각 4B 및 8B 파라미터로 압축하는 방법에 대한 포괄적인 보고서를 제공합니다. 두 가지 pruning 전략인 **depth pruning**(깊이 가지치기)와 **joint hidden/attention/MLP**(폭 가지치기)을 탐구하며, LM Evaluation Harness의 일반적인 벤치마크에서 결과를 평가합니다. 이 논문은 원본 데이터에 접근하지 않고도 distillation 데이터 세트에서 teacher 모델을 약간 조정하는 것이 유익하다는 것을 발견했습니다. 저자들은 Hugging Face에 기초 모델의 가중치를 공개했습니다.

**쉬운설명**:  
이 논문은 두 가지 대형 언어 모델을 작은 모델로 압축하는 방법을 설명합니다. 저자들은 모델을 작게 만드는 데 필요한 두 가지 방법을 연구하고, 이 작은 모델들이 실제로 잘 작동하는지를 테스트했습니다. 원본 데이터에 접근할 수 없더라도, 학습하는 과정에서 약간의 조정이 효과적이라는 것을 발견했습니다. 이 모델들은 다른 사람들도 사용할 수 있도록 공개되었습니다.

**관련분야**: 자연어 처리, 기계 학습, 모델 압축  
**추천수**: 16  
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2408.11796)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11745.png)
## 제목: FocusLLM: Scaling LLM's Context by Parallel Decoding
**요약**:  
이 논문에서는 LLM이 긴 문맥 정보에서 중요한 정보를 활용할 수 있도록 하는 것을 목표로 합니다. 기존의 변환기 아키텍처로는 긴 문맥을 처리하는 데 많은 자원이 필요하기 때문에, FocusLLM이라는 프레임워크를 제안합니다. 이 프레임워크는 긴 텍스트 입력을 모델의 원래 문맥 길이에 따라 청크로 나누어 처리합니다. 각 청크에 로컬 문맥을 추가하여 중요한 정보를 추출하고, 새롭게 고안한 병렬 디코딩 메커니즘으로 통합합니다. FocusLLM은 큰 비용 없이 8K 입력 길이로 훈련되어 여러 가지 긴 문맥 작업에서 뛰어난 성과를 보입니다.

**쉬운설명**:  
이 논문은 LLM이라는 언어 모델이 긴 글을 더 효율적으로 처리하는 방법을 설명합니다. 저자들은 글을 여러 조각으로 나누고, 각 조각에서 중요한 내용을 추출해내는 방법을 제안합니다. 이 과정에서 효율성을 높이기 위해 스마트한 방식으로 긴 글을 처리하며, 400K 토큰까지도 잘 작동하는 특별한 모델입니다.

**관련분야**: 자연어 처리, 기계 학습, 모델 최적화  
**추천수**: 4  
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2408.11745)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11475.png)
## 제목: TrackGo: A Flexible and Efficient Method for Controllable Video Generation
**요약**:  
최신 연구에서는 확산 기반의 제어 가능한 비디오 생성에서 상당한 발전이 있었습니다. 그러나 복잡한 시나리오에서 정밀하게 제어하는 것은 여전히 도전 과제가 됩니다. 이 논문에서는 자유형 마스크와 화살표를 이용한 TrackGo라는 새로운 접근 방식을 제안하며, 사용자들이 비디오 콘텐츠를 유연하게 조작할 수 있도록 합니다. TrackAdapter라는 효율적인 어댑터도 제안하며, 이는 사전 훈련된 비디오 생성 모델의 시간적 자기 주의 층에 통합됩니다. 그 결과 TrackGo는 중요한 지표들에서 최신 성과를 달성했습니다.

**쉬운설명**:  
이 논문은 사람들에게 비디오를 더 쉽게 조정할 수 있도록 하는 방법을 설명합니다. TrackGo라는 새로운 시스템을 통해 사용자는 비디오의 특정 부분을 유연하게 조절할 수 있습니다. 특히, TrackAdapter라는 작은 도구를 사용하여 기존 비디오 제작 모델을 개선하였습니다. 실험 결과로는 여러 평가 지표에서 최고의 성적을 기록했습니다.

**관련분야**: 비디오 생성, 컴퓨터 비전, 머신 러닝  
**추천수**: 3  
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2408.11475)