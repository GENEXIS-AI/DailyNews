![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08910.png)
## 제목: InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU

**요약**:
현대의 대형 언어 모델(Large Language Models, LLMs)에서는 긴 문맥을 처리하는 데에 있어 몇 가지 문제점이 있습니다. 긴 문맥은 추론 속도를 느리게 하고 메모리 사용량을 증가시킵니다. 게다가 대부분의 LLMs는 처음 훈련된 시퀀스 길이를 넘어서는 범위를 일반화하지 못합니다. 이러한 문제를 해결하기 위해 InfiniteHiP라는 새로운 LLM 추론 프레임워크를 제안합니다. 이 프레임워크는 모듈화된 계층적 토큰 제거 알고리즘을 통해 불필요한 문맥 토큰을 동적으로 제거하여 처리 속도를 높입니다. InfiniteHiP는 엔지니어링 간섭 없이 최장 3백만 개 토큰의 문맥을 단일 GPU에서 처리 가능하게 하고, 1백만 토큰 문맥을 18.95배 빠르게 디코딩할 수 있도록 합니다.

**쉬운설명**:
이 논문은 거대한 언어 모델들이 긴 문장이나 글을 읽을 때 어떻게 더 효율적으로 이해하고 처리할 수 있는지를 다루고 있습니다. InfiniteHiP라는 기술을 통해 컴퓨터는 더 적은 메모리로 더 많은 글을 빠르게 해석할 수 있게 됩니다.

**관련분야**:
인공지능, 자연어 처리(Natural Language Processing), 언어 모델

**추천수**:
68

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2502.08910)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08946.png)
## 제목: The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding

**요약**:
이 연구는 대형 언어 모델(LLM)이 정말로 말하는 내용을 이해하는지를 체계적으로 조사했습니다. 물리적 개념 이해 과제인 PhysiCo를 제안하여 모델이 단순 암기 대신 실제 이해를 할 수 있도록 돕습니다. 연구 결과, 최신 LLMs는 인간보다 약 40% 뒤처져 있음을 알렸습니다. 이는 이러한 모델들이 개념을 설명하고 언어로 인식할 수 있지만, 본 과제에서는 실패한 것을 보여줍니다. 또한 본 과제는 모델의 내재적인 어려움 때문에 도전적입니다.

**쉬운설명**:
이 논문은 컴퓨터가 물리적인 원리를 얼마나 잘 이해할 수 있는지를 알아보는 실험을 진행한 내용입니다. 컴퓨터가 말로는 잘 설명하지만, 실제로 물리적 개념을 이해하는 데 한계가 있다는 것을 발견했습니다.

**관련분야**:
인공지능, 기계학습, 자연어 처리

**추천수**:
41

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2502.08946)