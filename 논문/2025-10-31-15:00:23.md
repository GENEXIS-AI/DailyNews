![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26583.png)
## 제목:
Emu3.5: Native Multimodal Models are World Learners

**요약**:
이 논문은 Vision과 Language의 다음 상태를 예측하는 Emu3.5라는 대규모 멀티모달 세계 모델을 소개합니다. Emu3.5는 대규모 강화 학습을 통해 멀티모달 추론과 생성 능력을 향상시키고, 단변량 예측을 빠른 양방향 예측으로 전환하는 DiDA(Discrete Diffusion Adaptation)를 제안하여 약 20배의 추론 속도를 제공합니다. Emu3.5는 다양한 시나리오와 작업에서 일관된 세계 탐색과 조작이 가능하며, 커뮤니티 연구를 위해 오픈소스로 제공됩니다.

**쉬운설명**:
Emu3.5는 그림과 글을 동시에 이해하고 생성할 수 있는 모델이에요. 인터넷 비디오에서 학습하여, 그림과 글이 섞인 데이터를 잘 처리할 수 있답니다. 이 모델은 장기적인 예측과 복잡한 이미지 생성에서 뛰어난 성능을 보여줍니다.

**관련분야**:
인공지능, 컴퓨터 비전, 자연어 처리, 멀티모달 학습

**추천수**: 
29

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2510.26583)
---