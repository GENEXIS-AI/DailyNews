![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.13147.png)
## 제목: Are Your LLMs Capable of Stable Reasoning?
**요약**: 이 논문은 대형 언어 모델(LLMs)의 추론 능력을 현실 세계 응용에서 평가하는 방법에 문제점이 있으며, 이를 개선하기 위한 새로운 평가 지표와 벤치마크에 대해 설명합니다. 저자들은 G-Pass@k라는 새로운 평가 지표를 도입하여 모델의 최고 성능과 안정성을 평가하며, 동적 벤치마크인 LiveMathBench를 제안합니다. 이 벤치마크는 복잡한 수학 문제로 구성되어 있습니다. 실험 결과, LLM들의 '현실적인' 추론 능력에서 개선의 여지가 많다는 것이 밝혀졌습니다.

**쉬운설명**: 이 논문은 언어 모델이 얼마나 안정적으로 문제를 잘 풀 수 있는지를 평가하는 새 방법과 이를 테스트하는 수학 문제집 같은 것을 개발했습니다. 이를 통해 언어 모델이 실제로 얼마나 잘할 수 있는지 더 잘 알 수 있게 되었습니다.

**관련분야**: 인공지능, 자연어 처리, 기계 학습

**추천수**: 9

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.13147)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.12606.png)
## 제목: Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models
**요약**: 이 연구는 대규모 멀티모달 모델(LMMs)이 실제 시나리오에서 인간의 다양한 요구를 만족하는지를 평가할 수 있는 새로운 벤치마크인 Multi-Dimensional Insights (MDI)를 제안합니다. MDI 벤치마크는 500개 이상의 이미지를 포함하며, 각 이미지에는 모델의 이해능력과 논리적 분석능력을 평가하기 위한 두 가지 유형의 질문이 제공됩니다. 이 벤치마크는 연령별로 카테고리를 나누어 모델의 다양한 인구 집단에 대한 대응 능력을 평가합니다.

**쉬운설명**: 이 연구는 컴퓨터가 사진을 보고 이해하는 능력을 시험할 수 있는 새로운 문제집을 만들었습니다. 이 문제집으로 나이별로 사람들의 요구를 얼마나 잘 이해하는지 시험해볼 수 있습니다.

**관련분야**: 인공지능, 멀티모달 처리, 기계 학습

**추천수**: 8

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.12606)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.13018.png)
## 제목: OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain
**요약**: 이 논문은 재정 분야에서 Retrieval-Augmented Generation (RAG) 기술의 평가를 위한 온디렉셔널 및 자동화된 벤치마크 OmniEval을 소개합니다. 이 벤치마크는 다양한 쿼리 시나리오를 구조적으로 평가하는 매트릭스 기반의 평가 시스템을 특징으로 하며, 자동 생성과 인간 주석이 결합된 데이터 생성 방법을 사용합니다. 또한, 이 시스템은 검색과 생성 성능을 모두 평가하는 다단계 평가 시스템입니다.

**쉬운설명**: 이 논문은 금융 분야에서 정보 검색과 생성 능력을 동시에 평가할 수 있는 새로운 시험 시스템을 개발했습니다. 이를 통해 더 정확하고 유용한 금융 정보를 제공할 수 있는 방법을 찾을 수 있습니다.

**관련분야**: 인공지능, 정보 검색, 금융 데이터 분석

**추천수**: 6

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.13018)