![Image](https://avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg)

## 제목: InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions
**요약**: 이 연구는 인간의 인지능력과 유사하게 환경과 장기간 상호 작용할 수 있는 AI 시스템 개발을 목표로 한다. 멀티모달 대규모 언어 모델(MLLM)의 최근 발전에도 불구하고, 지속적이고 동시적인 스트리밍 인식, 메모리, 추론의 도전은 여전히 해결되지 않았다. 이 프로젝트는 단일 모델에 의존하는 대신, 분리된 스트리밍 인식, 추론 및 메모리 메커니즘을 도입하여 실시간 상호작용을 가능하게 하는 InternLM-XComposer2.5-OmniLive(IXC2.5-OL) 프레임워크를 제안한다. 주요 모듈은 실시간으로 멀티모달 정보를 처리하는 스트리밍 인식 모듈, 단기 기억을 장기 기억으로 압축하여 효율적인 검색을 돕는 멀티모달 장기 기억 모듈, 사용자의 쿼리에 반응하고 추론 작업을 수행하는 추론 모듈로 구성된다.
**쉬운설명**: 이 논문은 영상을 보면서 동시에 생각하고 기억할 수 있는 AI 시스템을 개발하려는 연구입니다. 사람처럼 기억과 추론을 하여 실시간으로 반응할 수 있는 AI 시스템을 만드는 것이 목표입니다.
**관련분야**: 멀티모달 인공지능, 대규모 언어 모델
**추천수**: 32
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.09596)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.08737.png)

## 제목: Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions
**요약**: 이 논문은 멀티모달 대규모 언어 모델(MLLM)의 저수준 시각적 지각 능력 개선을 목표로 한다. 이를 위해 2D 기하 정보를 정확하게 전달하는 Geoperception 벤치마크를 소개하고, 이를 통해 기존의 모델들이 가진 한계를 밝히는 한편, 성능 개선을 위한 모델 아키텍처, 훈련 기법 등을 탐구한다. 특히 시각적 세부사항을 정확히 설명하기 위한 합성 데이터의 사용과 데이터 커리큘럼으로 얻은 성과를 바탕으로 Euclid라는 새로운 모델을 제안한다.
**쉬운설명**: 이 논문은 컴퓨터가 이미지를 보고 정확히 설명할 수 있는 능력을 키우려고 하는 연구입니다. 여러 기술을 활용하여 이러한 능력을 개선하려고 했습니다.
**관련분야**: 멀티모달 학습, 시각 인식
**추천수**: 15
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.08737)

---