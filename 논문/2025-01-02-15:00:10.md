![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.19638.png)

## 제목: Xmodel-2 Technical Report

**요약**: Xmodel-2는 추론 작업에 특화된 1.2억 파라미터의 대규모 언어 모델입니다. 이 모델의 아키텍처는 다양한 모델 크기 간에 통일된 하이퍼파라미터 집합을 공유하도록 설계되어, 작은 모델에 대한 광범위한 실험이 가능하며 최적의 설정을 더 큰 모델로 원활하게 이전할 수 있습니다. 훈련 효율성과 안정성을 극대화하기 위해 MiniCPM의 WSD 학습률 스케줄러를 사용하였습니다. 1.5조 개의 다양한 소스의 토큰으로 사전 학습된 Xmodel-2는 복잡한 추론과 에이전트 기반 작업에서 최신 성능을 달성하면서 낮은 훈련 비용을 유지하고 있습니다. 이러한 결과는 효율적인 모델 설계와 훈련 전략이 추론 능력을 향상시키는 잠재력을 가지고 있음을 강조합니다. 모델 체크포인트와 코드는 [GitHub](https://github.com/XiaoduoAILab/Xmodel-2)에서 공개되어 있습니다.

**쉬운 설명**: Xmodel-2는 복잡한 문제를 해결하는 데 뛰어난 대규모 AI 모델입니다. 이 모델은 파라미터 설정을 공유하여 더 작은 모델로 실험한 결과를 쉽게 큰 모델에 적용할 수 있습니다. 1.5조 개의 문장에서 배운 이 모델은 빠르게 배우고, 비용도 적게 들면서 최고 성능을 내고 있습니다. 모든 훈련 정보와 코드는 GitHub에서 찾을 수 있습니다.

**관련 분야**: 자연어 처리, 인공지능, 추론

**추천수**: 2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2412.19638)