![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17481.png)
## 제목:
MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models
**요약**:
대형 언어 모델(LLM)은 많은 수의 파라미터로 인한 중복이 많은데 이 문제를 해결하기 위해 MaskLLM이라는 학습 가능한 가지치기 기법을 소개합니다. 이 방법은 N:M 구조적 희소성을 모델로 하여 컴퓨팅 오버헤드를 줄이는 것을 목표로 합니다. Gumbel Softmax 샘플링을 통해 N:M 패턴을 학습 가능하도록 분포로 모델링합니다. 이 접근법은 다음 두 가지 주요 이점을 제공합니다:
1. 대규모 데이터셋에서도 고품질의 마스크 학습
2. 도메인 또는 작업 전반에서 희소성의 전이 학습 

MaskLLM은 다양한 LLM에서 평가되었으며, 기존의 방법보다 놀라운 성능을 보여줍니다. 예를 들어, Wikitext에서 6.72의 PPL을 기록하며 고품질의 마스크만 학습하여 기존 최첨단 방법보다 낮은 PPL을 달성했습니다. 

**쉬운설명**:
대형 언어 모델은 많은 데이터를 처리하기 위해 매우 많은 파라미터를 가지고 있는데, 이로 인해 중복이 많이 생깁니다. MaskLLM은 이 문제를 해결하기 위해 어떤 파라미터를 줄일지 학습하는 방법입니다. 이 방법은 대형 모델에서도 적은 계산으로 높은 성능을 유지할 수 있게 해줍니다.

**관련분야**:
AI, 기계 학습, 신경망 구조 최적화

**추천수**:
29

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17481)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18125.png)
## 제목:
LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness
**요약**:
최근의 대형 다중모달 모델(LMM)은 2D 시각 이해 작업에서 뛰어난 성능을 보입니다. 그러나 3D 인식은 대규모 3D 비전-언어 데이터셋과 강력한 3D 인코더의 부재로 인해 발전이 저해되었습니다. 이 논문에서는 간단하고 효율적인 프레임워크인 LLaVA-3D를 소개합니다. LLaVA-3D는 LLaVA의 강력한 2D 이해 능력을 활용하여 3D 장면 이해로 효율적으로 적응시킵니다. 이를 위해 3D 패치를 사용하여 2D CLIP 패치 특징을 3D 공간의 대응 위치와 연결합니다. 실험 결과, LLaVA-3D는 기존의 3D LMMs보다 3.5배 더 빠르게 수렴하며, 다양한 3D 작업에서 최첨단 성능을 달성합니다.

**쉬운설명**:
현재 기술은 2D 이미지나 영상에서 정보를 잘 이해할 수 있지만, 3D 환경은 아직 어렵습니다. LLaVA-3D는 이를 해결하기 위해 2D 이해 기술을 활용하여 3D 환경에서도 잘 작동하도록 만든 방법입니다.

**관련분야**:
AI, 컴퓨터 비전, 3D 데이터 처리

**추천수**:
21

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.18125)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18042.png)
## 제목:
EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions
**요약**:
GPT-4o는 다양한 감정과 톤을 가진 음성 대화를 가능하게 하는 다중모달 모델입니다. 공개 데이터로 다중모달 언어 모델을 구축하는 것은 여전히 도전 과제입니다. EMOVA는 언어 모델에 감정과 음성을 통합한 멀티모달 능력을 제공합니다. 이 모델은 가벼운 스타일 모듈을 도입하여 다양한 감정 및 음성 스타일을 제어할 수 있습니다. EMOVA는 최첨단 성능을 달성하며, 비전-언어와 음성 벤치마크에서 선도적인 성능을 보여줍니다.

**쉬운설명**:
EMOVA는 언어 모델이 감정을 포함한 다양한 음성을 이해하고 생성할 수 있도록 만든 기술입니다. 이 모델은 더 자연스러운 대화를 가능하게 해줍니다.

**관련분야**:
AI, 자연어 처리, 음성 인식 및 생성

**추천수**:
21

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.18042)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17422.png)
## 제목:
Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction
**요약**:
대형 언어 모델(LLM)은 긴 문맥을 처리할 수 있지만, 이는 높은 계산 자원과 지연을 초래합니다. 이 연구는 LLM의 추론을 가속화하고 GPU 메모리 소비를 줄이는 새로운 접근법을 소개합니다. 초기 레이어에서 중요한 토큰을 식별하여 입력 토큰의 길이를 크게 줄일 수 있습니다. GemFilter라는 이 알고리즘은 기존의 방법보다 속도와 메모리 효율성에서 상당한 개선을 보여줍니다.

**쉬운설명**:
긴 문맥을 이해하는 모델은 높은 비용이 따릅니다. 이 논문은 초기 단계에서 중요하지 않은 정보를 걸러내어 계산을 더 빠르고 적게 만드는 방법을 제안합니다.

**관련분야**:
AI, 자연어 처리, 신경망 최적화

**추천수**:
14

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17422)
---