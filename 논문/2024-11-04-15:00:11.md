![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.00412.png)
## 제목:
Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation

**요약**:
이 논문은 과학 문제 해결에 사용하는 대형 언어 모델(LLMs)이 복잡한 문제에서는 종종 오류를 발생시키며, 도구 사용을 통해 이 문제를 해결할 수 있지만 이는 도구의 과도한 의존으로 이어질 수 있다고 지적합니다. 이에 연구팀은 인간 전문가와 유사한 문제 해결 전략을 LLM에 적용할 수 있는 새로운 두 가지 컴포넌트의 미세 조정 방법을 제안합니다. 첫 번째 컴포넌트는 'World Knowledge Distillation (WKD)'로, 도구로부터 얻은 해결책을 통해 도메인 지식을 직접 학습하게 합니다. 두 번째 컴포넌트는 'Tool Usage Adaptation (TUA)'이며, 문제를 쉬운 것과 어려운 것으로 분할하여 모델의 직접 응답 정확도를 기준으로 분류하고, 어려운 문제에 대해서는 도구 사용을 선택하도록 훈련합니다. 이 방법은 수학, 기후 과학, 역학 등 과학적 벤치마크 데이터셋 6개에서 평균 28.18%의 답변 정확도 개선과 13.89%의 도구 사용 정확도를 향상시켰습니다.

**쉬운설명**:
이 논문에서는 대형 언어 모델이 과학 문제를 해결할 때 종종 어려움을 겪는데, 이를 개선하기 위해 도구를 적절히 사용할 수 있도록 두 가지 방법을 고안했습니다. 첫 번째는 도구를 사용해 문제 해결 방법을 학습하고, 두 번째는 문제가 쉬운지 어려운지를 판단해 어려운 경우 도구를 사용하도록 하는 방법입니다.

**관련분야**:
인공지능, 머신러닝, 자연어 처리

**추천수**:
7

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2411.00412)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.00776.png)
## 제목:
Randomized Autoregressive Visual Generation

**요약**:
이 연구에서는 이미지 생성 분야에서 새롭게 제안한 모델링 방식인 Randomized AutoRegressive (RAR) 방식을 소개합니다. RAR 모델은 언어 모델 프레임워크와 완벽하게 호환되며 이미지 생성 작업에서 최고의 성능을 설정했습니다. 주요 아이디어는 표준 오토레그레시브 학습 과정에서 순차적으로 토큰을 예측하는 일반적인 방법 대신, 입력 시퀀스를 임의로 변환시키는 것입니다. 이를 통해 모델은 다양한 순서를 학습함으로써 양방향 문맥을 더욱 효과적으로 모델링할 수 있습니다. RAR 모델은 ImageNet-256 데이터셋에서 경쟁력 있는 FID 점수를 획득하며 이전의 디퓨전 기반 및 마스크 트랜스포머 기반 방법들을 뛰어넘었습니다.

**쉬운설명**:
이 논문은 이미지 생성 모델에서 새로운 방법을 소개합니다. 이 방법은 이미지를 만들면서 예측할 순서를 무작위로 바꿔가며 얼마나 효과적으로 이미지를 만들어 낼 수 있는지를 학습하게 합니다. 이를 통해 더 뛰어난 이미지 생성 성능을 보여주었습니다.

**관련분야**:
컴퓨터 비전, 이미지 처리, 기계 학습

**추천수**:
6

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2411.00776)

---

추가적인 논문 요약이 필요하시면 말씀해 주세요.