![Image](https://avatars/14e5794307e4672b1b51d26b31227e0f.svg)
## 제목:
LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA

**요약**:
본 논문에서는 Long-context Large Language Models (LLMs)이 사용자 질문에 대해 긴 텍스트를 기반으로 답변을 생성할 수 있도록 하고, 이 과정에서 정확한 문장 수준의 인용을 포함시켜 신뢰성과 검증 가능성을 높이는 방법을 제안합니다. 이를 위해 LongBench-Cite이라는 자동화된 벤치마크를 도입해 현재 LLM이 Long-Context Question Answering with Citations (LQAC)에서 얼마나 성능을 발휘하는지 평가합니다. 그 후, Coarse to Fine (CoF)이라는 새로운 파이프라인을 제안하여, 정확한 문장 수준의 인용을 포함한 긴 텍스트 QA 사례를 자동으로 생성하고, 이를 통해 LongCite-45k라는 대규모 SFT 데이터셋을 구축합니다. 최종적으로 LongCite-8B와 LongCite-9B 모델을 훈련하여 단일 출력으로 정확한 응답과 세밀한 문장 수준의 인용을 생성할 수 있도록 합니다. 평가 결과, 이러한 모델은 GPT-4o를 포함한 최신의 독점 모델을 능가하는 성능을 발휘합니다.

**쉬운설명**:
길고 복잡한 텍스트에서 사용자의 질문에 답할 때, 그 답변이 어디서 나왔는지 문장 단위로 인용하는 기술을 개발한 논문입니다. 이를 통해 답변의 신뢰성과 검증 가능성을 높일 수 있습니다. 새로운 방법을 통해 데이터셋을 만들고 그 데이터로 모델을 훈련하여 정확하고 신뢰할 수 있는 답변을 생성하는 데 성공했습니다.

**관련분야**:
자연어 처리 (NLP), 기계 학습, 텍스트 마이닝

**추천수**:
10

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.02897)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.02634.png)
## 제목:
Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency

**요약**:
본 논문에서는 오디오 기반의 인간 비디오 생성에서 자연스러운 움직임과 초상화 디테일을 개선하는 Loopy라는 새로운 비디오 확산 모델을 제안합니다. 기존 방식은 오디오 신호만으로는 인간의 움직임을 통제하기 어렵기 때문에 추가적인 공간 신호를 사용하여 움직임을 안정화시켰으나, 이는 자연스럽고 자유로운 움직임을 해칠 수 있습니다. Loopy는 오디오 신호만으로 동작을 제어하면서 장기적인 움직임 정보를 활용하여 보다 자연스러운 움직임 패턴을 학습합니다. 실험 결과, Loopy는 최근의 오디오 기반 초상화 확산 모델을 능가하여 더 생동감 있고 고품질의 결과물을 제공함을 보여줍니다.

**쉬운설명**:
음성만 듣고 사람의 얼굴 동영상을 만드는 기술을 더 자연스럽게 만드는 방법에 대한 연구입니다. 기존 방법보다 자연스럽고 곧고 고품질의 동영상을 만들 수 있는 기술을 제안합니다.

**관련분야**:
컴퓨터 비전, 딥러닝, 오디오 처리

**추천수**:
4

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.02634)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.02813.png)
## 제목:
MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark

**요약**:
이 논문은 광범위한 멀티모달 이해와 추론을 평가하는 엄격한 벤치마크인 MMMU-Pro를 소개합니다. MMMU-Pro는 텍스트 모델만으로는 답할 수 없는 질문을 걸러내고, 후보 옵션을 강화하며, 질문을 이미지 내에 삽입하여 진정으로 "보고" "읽는" 능력을 테스트합니다. 실험 결과, MMMU-Pro에서 모델 성능은 기존의 MMMU보다 상당히 낮음을 보여주며, 이를 통해 멀티모달 AI의 현실적 평가 도구로서 중요한 방향을 제시합니다.

**쉬운설명**:
텍스트와 이미지를 동시에 이해하고 추론하는 모델을 평가하기 위해 더 엄격한 테스트 기준을 만든 연구입니다. 이 테스트를 통해 모델들의 실제 성능을 더 정확하게 평가할 수 있습니다.

**관련분야**:
멀티모달 인공지능, 기계 학습, 컴퓨터 비전

**추천수**:
2

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.02813)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.02326.png)
## 제목:
Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining

**요약**:
이 논문은 코드 도메인에서 고품질 데이터를 사용하는 효율적인 사전훈련 방법을 제시합니다. Arctic-SnowCoder-1.3B라는 모델은 555B 토큰을 사용해 세 단계의 점진적인 데이터 정제를 통해 훈련되었습니다. 이를 통해 코드 생성 벤치마크에서 첨단 성능을 달성하며, 이러한 디자인 선택의 타당성을 입증합니다. 고품질 데이터가 중요한 이유를 다양한 벤치마크 결과를 통해 설명합니다.

**쉬운설명**:
코드 생성 모델을 더 잘 훈련시키기 위해 고품질 데이터가 얼마나 중요한지를 실험으로 증명한 연구입니다. 세심하게 선택된 훈련 데이터를 사용해 기존 모델보다 높은 성능을 달성했습니다.

**관련분야**:
프로그래밍 언어 처리, 기계 학습, 소프트웨어 공학

**추천수**:
0

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.02326)