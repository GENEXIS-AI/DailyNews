![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.16153.png)
## 제목:
**AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs**

**요약**:
이 논문은 새롭고 메모리 증강된 강화 학습 패러다임을 제안하여 에피소드 메모리와 신경 사례 선택 정책을 사용하여 LLM 에이전트가 지속적으로 학습할 수 있도록 합니다. 이를 통해 LLM을 직접 튜닝하지 않고도 적응형 학습을 수행할 수 있습니다.

**쉬운설명**:
LLM(대규모 언어 모델) 에이전트가 기존 데이터를 기억하고 스스로 학습할 수 있는 방법을 발전시킴으로써, 모델 자체를 바꾸거나 재조정하지 않고도 새로운 정보에 적응할 수 있도록 돕는 새로운 기술을 설명하는 연구입니다.

**관련분야**:
인공지능, 강화 학습, 대규모 언어 모델

**추천수**:
17

**PDF 다운로드 링크**:
![PDF 다운로드](https://arxiv.org/pdf/2508.16153)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.13650.png)
## 제목:
**CRISP: Persistent Concept Unlearning via Sparse Autoencoders**

**요약**:
CRISP는 희소 오토인코더를 활용한 방법으로, 대규모 언어 모델에서 원치 않는 지식을 효율적으로 제거하면서도 모델의 유용성을 유지할 수 있는 방법을 제안합니다.

**쉬운설명**:
컴퓨터가 필요 없는 정보를 지우고 필요한 정보만 잘 기억할 수 있는 새로운 방법을 개발한 연구입니다. 이 기술은 오토인코더라는 모델을 사용하여 모델이 필요 없는 정보를 쉽게 지우도록 합니다.

**관련분야**:
인공지능, 머신러닝, 데이터 처리

**추천수**:
8

**PDF 다운로드 링크**:
![PDF 다운로드](https://arxiv.org/pdf/2508.13650)

---