![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.09388.png)

## 제목:
**Qwen3 Technical Report**

**요약**:
이 논문에서는 최신 Qwen 모델 가족의 일환으로 Qwen3를 소개합니다. Qwen3는 성능, 효율성, 다국어 기능을 향상시키기 위해 설계된 대형 언어 모델(LLM) 시리즈입니다. Qwen3 시리즈는 '밀집형'(Dense) 및 '전문가 혼합'(MoE) 아키텍처의 모델로 구성되어 있으며, 매개변수 규모는 0.6억에서 235억에 이릅니다. Qwen3의 주요 혁신은 복잡한 멀티 스텝 추론을 위한 'thinking mode'와 빠른 문맥 중심 응답을 위한 'non-thinking mode'를 통합된 프레임워크로 통합한 것입니다. 이 통합 프레임워크는 채팅에 최적화된 모델(GPT-4o)과 추론 전용 모델(QwQ-32B) 간 전환의 필요성을 없애고 사용자 쿼리나 챗 템플릿에 따라 동적으로 모드를 전환할 수 있게 합니다. 또한, Qwen3는 추론 중에 계산 자원을 적응적으로 할당할 수 있는 '생각 예산'(thinking budget) 메커니즘을 도입하여 복잡한 작업에서 지연 시간과 성능을 균형있게 맞출 수 있게 합니다. 실험 결과, Qwen3는 코드 생성, 수학적 추론, 에이전트 작업 등의 다양한 벤치마크에서 대형 MoE 모델 및 독점 모델에 비해 경쟁력 있는 성능을 보였습니다. Qwen3는 이전 버전인 Qwen2.5보다 다국어 지원 언어 및 방언 수를 29에서 119로 확대하여 개선된 교차 언어 이해 및 생성 능력을 통해 글로벌 접근성을 향상시켰습니다. 모든 Qwen3 모델은 Apache 2.0에 따라 공개되어 학술 연구 및 개발을 위한 재현 가능성을 촉진합니다.

**쉬운설명**:
Qwen3는 AI 모델로 여러 언어를 이해하고 다양하게 사용할 수 있는 강력한 기능을 가지고 있어요. 빠른 응답과 복잡한 문제 해결을 동시에 할 수 있는 구조로, 사람들에게 더 많은 언어 서비스를 제공할 수 있게 된 거죠!

**관련분야**:
인공지능, 대형 언어 모델, 다국어 처리

**추천수**:
48

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2505.09388)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11409.png)

## 제목:
**Visual Planning: Let's Think Only with Images**

**요약**:
최근 대형 언어 모델(LLM)과 그 멀티모달 확장(MLLM)의 발전은 다양한 작업에서 기계 추론을 크게 향상시켰습니다. 그러나 이러한 모델은 주로 텍스트를 통해 추론을 표현하고 구조화하는 것에 의존합니다. 이 논문에서는 공간 및 기하학적 정보를 포함한 작업에서 언어가 항상 최선의 매체는 아닐 수 있다고 주장합니다. 따라서 텍스트와 상관없이 순수 시각적 표현을 통해 계획을 실행할 수 있는 새로운 패러다임, '비주얼 플래닝'(Visual Planning)을 제안합니다. 이 패러다임에서는 이미지들의 순서를 통해 시각적 영역에서 단계별 추론을 인코딩합니다. 우리는 대형 시각 모델의 훈련 후 개선을 위한 GRPO에 의해 강화되는 '강화 학습을 통한 비주얼 플래닝'(Visual Planning via Reinforcement Learning, VPRL) 프레임워크를 도입했으며, 대표적인 비주얼 내비게이션 작업들에서 관련성을 검증했습니다. 우리의 결과는 비주얼 플래닝이 텍스트 기반 추론을 위한 유망한 대안이 될 수 있음을 입증하고 있으며 직관적이고 이미지 기반의 추론의 이점을 지닌 새로운 작업들에 대한 길을 엽니다.

**쉬운설명**:
비주얼 플래닝은 이미지들만을 사용해서 생각하고 계획할 수 있는 방법이에요. 텍스트로 이해하기 어려운 경우 우리가 그림으로 쉽게 이해하듯이, AI도 이미지로 직접 계획하고 행동할 수 있게 도와주는 기술입니다.

**관련분야**:
강화 학습, 영상 인식, 인공지능

**추천수**:
4

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2505.11409)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.10962.png)

## 제목:
**MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation**

**요약**:
자동화된 정리 증명(ATP) 시스템은 AI의 엄청난 도전 과제 중 하나입니다. 기존의 단계별 증명기는 종종 편향된 검색 가이드로 인해 비효율적이고 최적이 아닌 증명 전략을 유도하곤 합니다. 본 논문에서는 이런 한계를 극복하기 위한 '다중 관점 검색 증명기(MPS-Prover)'를 소개합니다. MPS-Prover는 약 40%의 불필요한 학습 데이터를 성능 손상 없이 제거하는 포스트 트레이닝 데이터 큐레이션 전략과 다중 관점 트리 검색 메커니즘을 통합했습니다. 이 검색은 학습된 비판 모델과 전략적으로 설계된 휴리스틱 규칙을 통합하여 전술 선택을 다양화하며, 비생산적 상태에서의 고착을 방지하고 검색의 견고성을 향상시킵니다. 광범위한 평가 결과, MPS-Prover는 기존의 단계별 및 전체 증명 방식에 비해 더 짧고 다양한 증명을 생성하여 효율성과 효용성을 강조하며, 여러 까다로운 벤치마크에서 최첨단 성능을 달성했습니다.

**쉬운설명**:
MPS-Prover는 수학 정리 증명을 더 빠르고 효율적으로 할 수 있게 도와주는 AI 시스템입니다. 편견된 검색 방식으로 인한 비효율 문제를 해결하고 보다 다양한 방법으로 문제를 풀 수 있게 만들어 줍니다.

**관련분야**:
공식 추론, 인공지능, 증명 자동화

**추천수**:
3

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2505.10962)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11152.png)

## 제목:
**Learning Dense Hand Contact Estimation from Imbalanced Data**

**요약**:
손은 인간 상호작용에 필수적이며, 손과 세계 간의 접촉을 이해하는 것은 그 기능을 포괄적으로 이해하는 데 도움이 됩니다. 본 논문에서는 불균형한 데이터로부터 밀집한 손 접촉 추정 학습을 제안합니다. 손 접촉 데이터셋에서 대부분의 샘플이 접촉 상태가 아니라는 '클래스 불균형 문제'와 손가락 끝에서 주로 나타나는 '공간 불균형 문제'로 인해 발생하는 일반화의 어려움을 해결하기 위해 '균형 잡힌 접촉 샘플링'과 '정점 수준 클래스 균형(VCB) 손실'을 도입했습니다. 이를 통해 클래스 및 공간 불균형 문제 없이 대규모 손 접촉 데이터를 사용하여 밀집한 손 접촉 추정을 효과적으로 학습합니다.

**쉬운설명**:
이 연구는 불균형한 데이터를 이용해 손과 어떤 물건이 닿아 있는지를 더 잘 파악할 수 있도록 도와줍니다. 이렇게 하면 손이 어떻게 움직이고 상호작용하는지를 더 잘 이해할 수 있습니다.

**관련분야**:
컴퓨터 비전, AI 데이터 처리

**추천수**:
2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2505.11152)
---