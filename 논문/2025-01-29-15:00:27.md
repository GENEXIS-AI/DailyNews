![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17161.png)
## 제목:
SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training

**요약**:
이 논문은 슈퍼바이즈드 파인튜닝(SFT)과 강화 학습(RL)라는 두 가지 주요 포스트-트레이닝 기법의 역할을 모델의 일반화 능력 향상에 대한 비교를 중심으로 연구합니다. 텍스트 기반 규칙 변형과 시각적 변형에 집중하여 SFT와 RL이 각각 어떻게 작용하는지를 살펴봅니다. RL은 특히 결과 기반 보상을 통해 훈련될 때 모든 규칙 기반 텍스트 및 시각적 변형에 걸쳐 일반화되는 반면, SFT는 훈련 데이터를 기억하는 경향이 있어 Out-of-Distribution 시나리오에서는 일반화하기 어렵습니다.

**쉬운설명**:
이 논문은 기계가 학습 후 얼마나 잘 배울 수 있는지에 대해 두 가지 방법인 SFT와 RL을 비교한 것입니다. RL은 다양한 상황에 잘 적용되지만, SFT는 주어진 예시만 기억하고 새로운 상황에는 잘 대응하지 못하는 경향이 있습니다.

**관련분야**:
기초 모델(foundation models), 강화 학습(Reinforcement Learning), 기계 학습(Machine Learning)

**추천수**:
4

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.17161)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17116.png)
## 제목:
Optimizing Large Language Model Training Using FP4 Quantization

**요약**:
이 논문은 대용량 언어 모델의 효율적인 학습을 위한 FP4 양자화를 소개합니다. FP8 정밀도는 현재 실용적이지만, FP4는 양자화 오류와 표현 제한 문제 때문에 여전히 도전적입니다. 이 논문은 FP4 훈련 프레임워크를 제시하며, 차별적 양자화 추정기와 이상값 클램핑 및 보상 전략을 포함하여 이러한 문제를 해결했습니다. 혼합 정밀도 훈련 및 벡터 단위 양자화를 통해 안정성을 보장하며, FP4 프레임워크는 BF16과 FP8에 비해 거의 손실 없이 유사한 정확도를 달성합니다.

**쉬운설명**:
이 논문은 대형 언어 모델을 더 빠르게 학습시키는 방법을 다룹니다. FP4라는 새로운 기법을 활용해 기존보다 더 적은 자원으로 모델을 효과적으로 학습시킬 수 있습니다.

**관련분야**:
양자화(Quantization), 대형 언어 모델(Large Language Models), 기계 학습(Machine Learning)

**추천수**:
2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.17116)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16372.png)
## 제목:
Low-Rank Adapters Meet Neural Architecture Search for LLM Compression

**요약**:
이 논문은 저랭크 어댑터와 신경 네트워크 탐색(NAS)을 결합하여 대규모 언어 모델을 압축하고 파인튜닝하는 방법을 제시합니다. 이러한 조합을 통해 LLM의 사용이 더 저렴해지고, 메모리 소모는 줄어들며 처리 속도가 빨라져 실무적인 적용 가능성이 커집니다.

**쉬운설명**:
이 논문은 대형 언어 모델을 더 작게 만들고 빠르게 작동하도록 하는 방법을 소개합니다. 이렇게 하면 모델을 더 쉽게 사용할 수 있습니다.

**관련분야**:
모델 압축(Model Compression), 저랭크 어댑터(Low-Rank Adapters), 신경 아키텍처 탐색(Neural Architecture Search)

**추천수**:
2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.16372)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15747.png)
## 제목:
IndicMMLU-Pro: Benchmarking Indic Large Language Models on Multi-Task Language Understanding

**요약**:
이 논문은 지리적, 문화적으로 다양한 인도 아대륙의 언어들을 다루며, 그런 언어 모델의 발전을 위한 표준화된 평가 프레임워크를 소개합니다. 이 프레임워크는 여러 인도 언어에서의 다양한 태스크에 대한 성능을 평가합니다.

**쉬운설명**:
이 논문은 다양한 인도어들이 가지고 있는 복잡한 특징들을 평가하는 기준을 제시하였습니다. 이 기준으로 기계가 인도어들을 더 잘 이해할 수 있게 됩니다.

**관련분야**:
자연어 처리(Natural Language Processing), 다중언어 모델(Multi-Language Models), 벤치마킹(Benchmarking)

**추천수**:
2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.15747)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16975.png)
## 제목:
Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling

**요약**:
이 논문은 큰 언어 모델의 성능 개선을 위해 입력 어휘를 확장하는 새로운 방법을 제안합니다. 다중-그램 토큰을 활용하여, 모델 크기와 무관하게 성능을 높이는 로지선형 관계를 발견했습니다. 더 큰 입력 어휘를 사용하면 동일한 모델 크기의 결과를 두 배로 증가시킬 수 있으며, 토큰화의 중요성을 강조합니다.

**쉬운설명**:
이 논문은 언어 모델이 더 많은 단어를 학습하게 하여 더 나은 성능을 발휘할 수 있도록 하는 방법을 소개합니다. 많은 단어를 배우면 더 똑똑한 모델을 만들 수 있습니다.

**관련분야**:
언어 모델(Language Models), 토큰화(Tokenization), 기계 학습(Machine Learning)

**추천수**:
1

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.16975)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16496.png)
## 제목:
Open Problems in Mechanistic Interpretability

**요약**:
이 논문은 신경망이 가진 기능의 계산 메커니즘을 이해하려고 하는 기계적 해석 가능성의 현재 문제를 다룹니다. 이 분야에서 더 나은 방법론을 개발하고, 공학적 목표를 위해 어떤 질문에 우선순위를 두어야 하는지에 대한 논의가 포함돼 있습니다.

**쉬운설명**:
이 논문은 기계가 어떻게 결정을 내리는지 이해하려고 하는 연구의 여러 문제들을 다루고 있습니다. 이것은 기계를 더 안전하고 똑똑하게 만드는 것을 목표로 합니다.

**관련분야**:
기계 해석 가능성(Mechanistic Interpretability), 인공지능(AI), 머신러닝(Machine Learning)

**추천수**:
0

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.16496)