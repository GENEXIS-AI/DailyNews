![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.20670.png)
## 제목:
MMSearch-R1: 대규모 멀티모달 모델의 검색 능력 향상

**요약**:
이 논문은 MMSearch-R1이라는 강화학습 프레임워크를 소개합니다. 이 프레임워크는 대규모 멀티모달 모델(LMMs)이 실제 환경에서 효율적이고 즉각적인 다중 턴 검색을 수행할 수 있게 하여 기존 접근 방식을 능가합니다. MMSearch-R1은 다양한 층에서 각기 다른 정보를 통합하고, 이를 통해 학습된 모델은 복잡한 검색 작업을 더 빠르고 정확하게 처리할 수 있습니다.

**쉬운설명**:
MMSearch-R1은 여러 감각(예: 이미지, 텍스트)을 동시에 이해할 수 있는 대규모 모델들이 좀 더 똑똑하게 정보를 찾아낼 수 있도록 도와주는 시스템입니다. 예를 들어, 이미지를 보고 거기에 대한 설명을 찾거나, 텍스트를 보고 관련 이미지를 찾는 일을 더 잘 할 수 있게 해줍니다.

**관련분야**:
머신러닝, 강화학습, 멀티모달 AI

**추천수**:
25

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2506.20670)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.21551.png)
## 제목:
대규모 언어 모델의 사전훈련에서의 Grokking: 시험 없이 암기에서 일반화로의 전환 감시

**요약**:
이 논문은 대규모 언어 모델의 사전 훈련 과정에서 'Grokking', 즉 학습 손실이 수렴한 이후 테스트 성능이 지속적으로 개선되는 현상을 다룹니다. 이 연구는 암기(memory)에서 일반화(generalization)로의 전환 과정을 보여주며, 이는 모델이 점점 더 효과적으로 데이터를 이해하고 활용하게 된다는 것을 시사합니다.

**쉬운설명**:
대규모 언어 모델은 처음에는 개별 사례들을 많이 외우지만, 시간이 지날수록 더 많은 원칙을 이해해서 새로운 문제도 잘 해결할 수 있게 됩니다. 이 과정을 관찰하고 분석하는 것이 이 논문의 주요 내용입니다.

**관련분야**:
자연어 처리, 기계 학습, 모델 훈련

**추천수**:
9

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2506.21551)
---