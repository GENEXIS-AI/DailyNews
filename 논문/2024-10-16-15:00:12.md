### 전문요약

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.11710.png)
## 제목: MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models

**요약**:
이 논문은 대형 언어 모델(LLM)의 도구 사용 능력을 평가하기 위한 MTU-Bench라는 다중 세분화 벤치마크를 제안합니다. 기존 데이터셋의 제한점인 평가 시나리오 부족과 비용 문제를 해결하기 위해 MTU-Bench는 다양한 도구 사용 장면을 포함하며, 예측 결과에 따른 평가를 기반으로 합니다. 또한, 이 논문은 MTU-Instruct 데이터를 소개하여 LLM의 도구 사용 능력을 강화하고, 기존 고품질 데이터셋을 변환하여 실제 도구 사용 시나리오를 시뮬레이션합니다.

**쉬운설명**:
이 논문은 대형 언어 모델이 다양한 상황에서 얼마나 잘 도구를 사용할 수 있는지 평가하기 위한 새로운 기준을 만들었어요. 평가 비용을 낮추고, 더 다양한 상황을 포함하려고 했답니다.

**관련분야**: 인공지능, 머신러닝, 자연어 처리

**추천수**: 12
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2410.11710)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.11779.png)
## 제목: MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation

**요약**:
이 연구는 다중 모드 대형 언어 모델(MMLM)이 혼란 현상을 보이는 이유를 분석하고, 이를 해결하기 위한 동적 수정 디코딩 방법(DeCo)을 제안합니다. 기존의 시선과 달리 MLLM은 시각적 객체를 인식할 수 있지만 언어 모델의 지식 우선이 이를 억제하여 혼란을 초래한다고 봅니다. 이 방법은 다양한 디코딩 전략과 통합 가능하며, 실험 결과는 DeCo가 혼란률을 크게 줄이는 데 효과적임을 보여줍니다.

**쉬운설명**:
이 논문에서는 AI가 때때로 잘못된 정보를 생성하는 이유를 알아보고, 이를 줄이기 위한 새로운 방법을 제시했어요. AI가 시각적 정보를 잘 인식하지만, 그 정보가 제대로 활용되지 않아 착각을 불러일으킬 수 있답니다.

**관련분야**: 인공지능, 멀티모달 학습, 자연어 처리

**추천수**: 10
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2410.11779)
---

### 요청사항
전체 논문에 대한 전반적인 이해를 돕기 위해 전문적인 요약과 쉽게 이해할 수 있는 설명을 번갈아 가며 작성합니다. 각 논문에 대한 심화된 요약이 필요하시면 먼저 전문적 요약을 요청해주세요.