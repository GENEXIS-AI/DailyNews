![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.14922.png)
## 제목: RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response
**요약**: 이 논문은 대규모 언어 모델(Large Language Models, LLMs)이 노이즈 데이터를 포함한 상황에서 강건하게 작동하도록 하는 감독 하에 미세 조정(Fine-tuning) 기법인 RobustFT를 제안합니다. 이는 노이즈 반응 상황에서 모델 성능을 유지하게 하여, 보다 안정적인 응답 생성을 가능하게 합니다.

**쉬운설명**: 이 논문에서는 언어 모델이 잘못된 정보나 오류가 포함된 데이터에서도 잘 작동하도록 하는 방법을 제안합니다. 이렇게 하면 모델이 다양한 상황에서도 정확한 결과를 줄 수 있습니다.

**관련분야**: 인공지능, 자연어 처리, 기계학습

**추천수**: 78

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.14922)
---

![Image](/avatars/4d9f9a546aa8c63e277161ea700075c4.svg)
## 제목: Parallelized Autoregressive Visual Generation
**요약**: 이 논문에서는 이미지 생성을 위한 병렬화된 자기회귀적(Autoregressive) 방법을 제안합니다. 기존의 연속적인 이미지 생성 방식과 달리, 이 접근법은 병렬 처리를 통해 생성 속도를 향상시킵니다.

**쉬운설명**: 이 연구는 이미지를 더 빠르게 만들기 위한 새로운 방법을 찾아냈습니다. 여러 부분을 동시에 처리하여 이미지를 빨리 생성할 수 있습니다.

**관련분야**: 컴퓨터 비전, 인공지능, 생성 모델

**추천수**: 47

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.15119)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17256.png)
## 제목: B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners
**요약**: 이 논문은 셀프 러닝 시스템에서 탐색(Exploration)과 착취(Exploitation)를 조절하기 위한 새로운 프레임워크, B-STaR을 소개합니다. 모델이 새로운 정보를 학습하면서 동시에 기존 지식을 효율적으로 활용할 수 있게 합니다.

**쉬운설명**: 새로운 정보를 배우면서 이전 지식을 잘 활용할 수 있도록 도와주는 시스템에 관한 연구입니다.

**관련분야**: 강화학습, 기계학습, 인공지능

**추천수**: 38

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.17256)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17451.png)
## 제목: Diving into Self-Evolving Training for Multimodal Reasoning
**요약**: 이 논문에서는 다양한 모달리티를 다루는 모델의 자가 진화 학습 방법에 대해 논의합니다. 멀티모달 추론 과제를 개선하기 위해 스스로 발전하는 학습 알고리즘을 개발했습니다.

**쉬운설명**: 여러 종류의 데이터를 이용해 사고하는 모델이 스스로 더 똑똑해질 수 있는 방법을 연구했습니다.

**관련분야**: 멀티모달 인공지능, 기계학습

**추천수**: 37

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.17451)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17743.png)
## 제목: YuLan-Mini: An Open Data-efficient Language Model
**요약**: 효율적으로 데이터를 활용하는 언어 모델인 YuLan-Mini를 소개합니다. 이 기법은 제한된 데이터 환경에서도 높은 성능을 발휘할 수 있도록 설계되었습니다.

**쉬운설명**: 적은 데이터를 사용해도 잘 작동하는 언어 모델을 개발했습니다.

**관련분야**: 자연어 처리, 기계학습

**추천수**: 36

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.17743)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.16145.png)
## 제목: Offline Reinforcement Learning for LLM Multi-Step Reasoning
**요약**: 이 논문은 대규모 언어 모델의 다단계 추론을 위한 오프라인 강화학습 기법을 탐구합니다. 주어진 학습 데이터 세트 내에서 최적의 결정을 내리는 데 중점을 두고 있습니다.

**쉬운설명**: 복잡한 문제를 해결하기 위한 특별한 연습 방법에 대해 연구했습니다. 이 방법은 주변에서 배우는 것 없이 이미 가진 정보를 사용하는 방식입니다.

**관련분야**: 강화학습, 자연어 처리

**추천수**: 33

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.16145)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17153.png)
## 제목: Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching
**요약**: 이 논문은 이미지 자기회귀 모델에서 효율적인 샘플링을 위한 방법을 제안합니다. Flow Matching 기법을 통해 한 단계로 이미지 생성을 가능하게 합니다.

**쉬운설명**: 이미지를 만드는 과정을 단순화하여 더 빨리 만들 수 있는 새로운 방법을 찾았습니다.

**관련분야**: 컴퓨터 비전, 인공지능, 생성 모델

**추천수**: 32

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.17153)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18547.png)
## 제목: Token-Budget-Aware LLM Reasoning
**요약**: 이 논문에서는 토큰 예산을 고려한 대규모 언어 모델의 추론 방법을 제안합니다. 주어진 리소스 내에서 효율적인 언어 처리 및 추론을 가능하게 합니다.

**쉬운설명**: 제한된 리소스를 최대한 활용해 언어 문제를 해결하는 방법에 대해 설명합니다.

**관련분야**: 자연어 처리, 인공지능

**추천수**: 31

**PDF 다운로드 링크**: ![PDF 다운로드](https://huggingface.co/papers/2412.18547)
---