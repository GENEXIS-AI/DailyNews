![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.16191.png)
## 제목: HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models

**요약**: 이 논문은 대형 언어 모델(LLMs)의 긴 텍스트 생성 능력을 평가하기 위해 설계된 'HelloBench'라는 벤치마크를 소개합니다. HelloBench는 Bloom의 분류법에 따라 긴 텍스트 생성 작업을 5개의 하위 작업으로 분류하며, 인간 평가와 높은 상관관계를 유지하면서 평가 시간을 줄이는 'HelloEval'이라는 평가 방법도 제안합니다. 실험 결과, 대부분의 LLM이 4000자 이상의 긴 텍스트를 생성하는 데 어려움을 겪고 있다는 점을 관찰했습니다.    

**쉬운설명**: 이 논문은 대형 언어 모델이 얼마나 긴 글을 잘 쓸 수 있는지 평가하기 위한 새로운 방법을 소개합니다. 그 결과, 대부분의 대형 언어 모델이 긴 글을 쓰는 데 한계를 가지고 있다는 것을 발견했습니다.     

**관련분야**: 인공지능, 자연어 처리
**추천수**: 13
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.16191)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.15700.png)
## 제목: Making Text Embedders Few-Shot Learners

**요약**: 이 논문은 대형 언어 모델(LLMs)의 인컨텍스트 학습(ICL) 능력을 활용하여 텍스트 임베딩 품질을 향상시키는 새로운 모델 'bge-en-icl'을 소개합니다. 이 접근법은 쿼리 쪽에 태스크 관련 예시를 직접 통합하여 다양한 태스크에서 성능을 크게 향상시킵니다. 실험 결과, 새로운 SOTA 성능을 설정했음을 보여줍니다.

**쉬운설명**: 이 논문은 언어 모델이 몇 가지 예시만 보고도 높은 품질의 텍스트 임베딩을 생성하는 방법을 제안합니다. 그 결과, 다양한 태스크에서 성능이 크게 향상되었습니다.   

**관련분야**: 인공지능, 자연어 처리
**추천수**:10
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.15700)