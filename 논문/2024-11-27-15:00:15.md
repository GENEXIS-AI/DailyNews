![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17465.png)
## 제목:
ShowUI: One Vision-Language-Action Model for GUI Visual Agent

**요약**:
ShowUI 모델은 GUI 환경에서 사람과 비슷한 방식으로 UI를 인식하고 상호작용하는 비전-언어-액션 모델입니다. 이는 기존의 언어 기반 에이전트가 갖고 있는, 텍스트 중심의 정보에 대한 의존성을 해결하고자 고안되었습니다. 이 모델은 UI의 스크린샷을 UI 연결 그래프로 구성하여 컴퓨팅 비용을 줄이는 UI-가이드 비주얼 토큰 선택, 다양한 GUI 작업의 요구 사항을 효과적으로 관리하는 임베디드 비전-언어-액션 스트리밍, 그리고 데이터 균형 문제를 해결하기 위한 소규모 고품질 GUI 명령 데이터셋 등의 혁신을 포함하고 있습니다. ShowUI는 2B 모델 사이즈로 256K 데이터셋에서 학습되었으며, 스크린샷 바닥작업 정확도에서 75.1% 성능을 기록했습니다. 또한 훈련 중 33%의 중복 비주얼 토큰을 줄임으로써 성능이 향상되었습니다.

**쉬운설명**:
ShowUI라는 시스템은 우리가 컴퓨터 화면을 보고 작업하는 방식과 유사하게 컴퓨터도 화면을 인식하고 작업을 수행할 수 있도록 설계되었습니다. 기존의 시스템은 주로 글자와 텍스트 정보를 사용했지만, ShowUI는 화면 전체를 보고 분석하여 시스템이 효율적으로 작동하도록 도와주는 것입니다.

**관련분야**: 
컴퓨터 비전, 자연어 처리, 인간-컴퓨터 상호작용 

**추천수**: 22

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2411.17465)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17116.png)
## 제목:
Star Attention: Efficient LLM Inference over Long Sequences

**요약**:
Star Attention은 긴 시퀀스의 추론을 효율적으로 수행하기 위한 블록 희소 근사 두 단계 메커니즘을 도입하였습니다. 첫 번째 단계에서는 컨텍스트를 호스트 간 블록 단위로 지역적 주의를 병렬로 처리하고, 두 번째 단계에서 쿼리 및 응답 토큰은 모든 이전 캐시된 토큰들을 시퀀스 전역 주의를 통해 접합니다. 이를 통해 메모리 요구 사항을 줄이고 추론 시간을 최대 11배까지 줄이면서도 정확도는 95-100%의 수준을 유지할 수 있습니다.

**쉬운설명**:
'Star Attention'은 매우 긴 텍스트나 데이터를 빠르고 효율적으로 처리하기 위한 새로운 방법입니다. 이로 인해 컴퓨터가 많은 정보를 빠르게 분석하고 이해할 수 있게 됩니다.

**관련분야**: 
자연어 처리, 기계 학습, 인공지능

**추천수**: 8

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2411.17116)

---