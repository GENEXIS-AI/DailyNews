![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11896.png)
## 제목: AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning
**요약**: 이 논문은 대규모 언어 모델(LLM)의 추론 능력을 향상시키기 위해 체인-오브-폰트(Chain-of-Thought, CoT) 프롬프트를 효율적으로 사용하는 방법을 제안합니다. CoT는 복잡한 추론을 개선하지만 모든 쿼리에 대해 긴 reasoning 스텝을 생성함으로써 비효율성을 초래한다는 문제점을 가지고 있습니다. AdaCoT는 강화 학습을 통해 CoT를 트리거할 시기를 적응적으로 결정하고, Pareto 최적화를 통해 모델 성능과 CoT 트리거링의 빈도 및 계산 비용 사이의 균형을 찾습니다. 특히 Proximal Policy Optimization (PPO)을 활용하여 CoT 트리거링 결정 경계를 동적으로 조정하고, Selective Loss Masking (SLM) 기술로 여러 단계의 강화 학습 훈련에서 결정을 안정되게 합니다.

**쉬운설명**: 복잡한 문제를 풀 때, 컴퓨터 프로그램은 혼자서 긴 생각을 필요로 하지 않을 수 있습니다. AdaCoT는 강화 학습을 사용하여 언제 깊게 생각해야 하고 언제 바로 결론을 내야 할지를 효율적으로 결정하는 시스템입니다. 이 연구를 통해, 불필요한 과정을 줄이고 더 빠르고 효율적인 답변을 제공할 수 있습니다.

**관련분야**: 인공지능, 기계 학습, 자연어 처리, 강화 학습

**추천수**: 30

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2505.11896)
