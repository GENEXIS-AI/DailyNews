![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24024.png)

## 제목:
**AndroidLab: Android 자율 에이전트의 훈련 및 체계적인 벤치마킹**

**요약**:
이 논문은 안드로이드 자율 에이전트를 체계적으로 연구하고 평가하기 위한 프레임워크인 AndroidLab을 소개합니다. AndroidLab은 다양한 모달리티와 행동 공간, 그리고 재현 가능한 벤치마크를 포함한 운영 환경을 제공합니다. 안드로이드 가상 디바이스와 아홉 개의 앱에서 총 138개의 작업을 지원하도록 설계되었습니다. 이를 통해 대규모 언어 모델(LLM)과 멀티모달 모델(LMM)의 성공률을 크게 개선시킬 수 있었습니다.

**쉬운 설명**:
이 연구에서는 안드로이드 자율 에이전트를 더욱 효율적으로 연구하고 평가할 수 있는 툴인 AndroidLab을 개발했습니다. 이 시스템에서는 다양한 작업을 통해 에이전트가 얼마나 잘 동작하는지 확인할 수 있습니다.

**관련분야**:
자율 에이전트, 모바일 플랫폼, 벤치마킹

**추천수**:
19

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2410.24024)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.00836.png)

## 제목:
**DynaMath: 비전 언어 모델의 수학적 추론 강건성을 평가하는 동적 시각 벤치마크**

**요약**:
이 논문은 비전 언어 모델(VLM)의 수학적 추론 능력을 심도 있게 평가하기 위해 DynaMath라는 동적 시각 수학 벤치마크를 제안합니다. 이는 다양한 입력 조건에 따라 VLM의 일반화 능력을 평가할 수 있도록 설계되었습니다. 5,010개의 질문으로 14개의 최신 VLM을 평가한 결과, 최악의 경우 모델의 정확도는 평균보다 크게 낮다는 점을 밝혀냅니다.

**쉬운 설명**:
이 연구는 컴퓨터가 복잡한 수학 문제를 얼마나 잘 푸는지 다양한 방법으로 테스트할 수 있는 시스템을 개발했습니다. 이를 통해 모델의 실제 성능을 더 잘 이해할 수 있습니다.

**관련분야**:
비전 언어 모델, 수학적 추론, 인공지능 평가

**추천수**:
8

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2411.00836)

---