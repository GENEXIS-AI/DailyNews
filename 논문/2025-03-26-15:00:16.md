![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.19325.png)
## 긴 문맥 자가회귀 비디오 모델링을 이용한 다음 프레임 예측: Long-Context Autoregressive Video Modeling with Next-Frame Prediction
**요약**:
본 논문에서는 비디오 생성에서 상호의존하는 프레임을 효과적으로 모델링하기 위해 **Frame AutoRegressive (FAR)** 라는 새로운 기법을 제시합니다. 언어 모델에서와 유사하게, 이미지의 프레임 간 인과 관계를 학습하여 높은 수준의 비디오 생성을 가능하게 합니다. 기존의 **RoPE** 기법은 장기 비디오 문맥에서 효과적이지 않아 개선이 필요하며, 본 연구는 **FlexRoPE** 기법을 통해 이러한 문제를 해결하고자 합니다. 또한, **장단기 문맥 모델링**을 제시하여 더 효율적으로 높은 품질의 비디오 생성을 가능하게 합니다.

**쉬운설명**:
우리가 비디오를 만들 때, 한 장면과 그 다음 장면의 연결이 자연스러워야 하죠. 이 연구에서는 그런 자연스러운 모습을 만드는데 필요한 새로운 방법을 소개하고 있어요. 예를 들어, 책을 읽을 때 앞의 문장을 잘 이해해야 뒤의 문장도 잘 이해할 수 있는 것처럼, 이 연구에서는 각 장면 사이의 관계를 잘 파악하는 방법을 알려주고 있답니다!

**관련분야**:
컴퓨터 비전, 비디오 생성, 자가회귀 모델링

**추천수**: 42
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2503.19325)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.18931.png)
## CoMP: Vision Foundation Models의 계속적인 멀티모달 사전 학습
**요약**:
이 연구에서는 **Vision Foundation Models (VFMs)** 를 멀티모달 방법으로 계속 사전 훈련하여 시각 입력의 다양한 크기를 처리하고 시각 표현을 언어 표현과 맞추는 방법을 제안합니다. **CoMP**라는 이 시스템은 지속적인 회전 위치 임베딩과 이미지와 텍스트 특성 사이의 정렬 손실을 통해 멀티모달 표현을 정렬하는 세 단계 훈련을 사용하여 성능을 향상시킵니다.

**쉬운설명**:
이 연구에서는 컴퓨터가 그림과 글을 더 잘 이해하도록 돕는 방법을 설명하고 있어요. 그림과 글을 각자 배우던 기존 방식과 달리, 이 두 가지를 함께 배우도록 했어요. 그 결과 컴퓨터가 둘 다 잘 이해할 수 있게 되었답니다!

**관련분야**:
멀티모달 학습, 시각적 정보 처리

**추천수**: 15
**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2503.18931)
---

각 논문의 포맷대로 요약을 작성하였습니다. 다른 논문에 대한 추가 설명이 필요하시면 알려주세요!