### 논문 1: Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png)

**요약**: 이 논문은 기존의 'Supervised Fine-Tuning (SFT)' 대신 'Critique Fine-Tuning (CFT)' 방법을 제안합니다. CFT는 주어진 잘못된 응답을 비판하는 학습을 통해 언어 모델의 비판적 사고를 향상시키고자 합니다. 이 방법은 50,000개의 샘플을 사용한 데이터 세트를 기반으로 하며, 다양한 수학 기준에서 SFT에 비해 4-10% 향상을 보였습니다. 결과적으로, CFT는 고도의 추론 능력을 가진 모델을 만드는 데 효과적인 대안임을 주장합니다.

**쉬운설명**: 이 논문에서는 기존 방법이 올바른 답을 따라 학습하는 반면, 새로운 방법은 틀린 답을 비판적으로 분석하는 학습법을 사용하는데, 이 방법이 훨씬 더 뛰어난 성능을 낸다고 설명합니다.

**관련분야**: 인공지능, 자연어 처리, 언어 모델 학습

**추천수**: 6

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.17703)

---

### 논문 2: Atla Selene Mini: A General Purpose Evaluation Model

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png)

**요약**: Atla Selene Mini는 소규모 언어 모델로, 다양한 벤치마크에서 높은 성능을 보입니다. 본 논문은 데이터의 질을 높이기 위해 체계적인 데이터 개선 전략을 적용했습니다. Selene Mini는 인간 전문가 평가와 높은 일치도를 보이며, 실제 환경에서 사용하기에 적합한 평가 모델로 자리매김합니다. 또한, 모델 가중치가 공개되어 커뮤니티의 폭넓은 채택을 유도하고 있습니다.

**쉬운설명**: Atla Selene Mini는 여러 작업에서 높은 성능을 보이는 작은 언어 모델로, 다양한 사례에서 뛰어난 평가 능력을 자랑합니다.

**관련분야**: 인공지능, 모델 평가

**추천수**: 1

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.17195)

---

### 논문 3: Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png)

**요약**: 이 논문에서는 오픈AI의 o3-mini 모델에 대한 초기 외부 안전 테스트 경험을 공유합니다. 연구진은 ASTRAL 도구를 사용해 모델의 다양한 안전성 범주를 자동으로 평가했고, 이 과정에서 87개의 실제 안전 문제를 발견했습니다. 논문은 배포 전에 철저한 테스트가 필요함을 강조합니다.

**쉬운설명**: 이 논문은 새로 나온 모델의 안전성을 테스트하여 사용자에게 해가 되는 요소를 발견하고, 배포 전에 이러한 요소를 개선해야 한다고 설명합니다.

**관련분야**: 인공지능, 모델 안전성, 윤리적 고려

**추천수**: 1

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2501.17749)