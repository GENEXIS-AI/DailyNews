![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15279.png)
## 제목:
**VisuLogic: 대규모 다중 모드 언어 모델의 시각적 추론 평가를 위한 벤치마크**

**요약**:
시각적 추론은 인간 지능의 핵심 요소이며, 고급 다중 모드 모델에는 필수적인 능력입니다. 하지만 현재의 다중 모드 대규모 언어 모델(MLLMs)의 추론 평가에는 언어 중심의 추론이 많아 시각적 추론을 정확히 측정하지 못합니다. 이를 해결하기 위해 VisuLogic 벤치마크를 소개합니다. 이 벤치마크는 6개의 범주(정량적 변화, 공간적 관계, 속성 비교 등)에 걸친 1,000개의 인간 검증 문제로 구성되어 있으며, MLLMs의 시각적 추론 능력을 평가할 수 있습니다. 주요 MLLMs을 평가한 결과, 모델의 정확도가 대체로 30% 이하로 나타났으며, 이는 무작위 베이스라인인 25%보다 약간 높은 수준일 뿐이며, 인간이 달성한 51.4%에 비하면 현저히 낮춰져 시각적 추론의 큰 격차를 드러냅니다. 또한 우리는 추가적인 훈련 데이터셋과 강화 학습 베이스라인을 제공하여 더 나은 발전을 지원합니다.

**쉬운설명**:
두 가지 매체, 즉 텍스트와 이미지가 함께 활용되는 모델들이 얼마나 시각적인 이해를 잘 할 수 있는지를 평가하기 위해 새로운 기준이 제시되었습니다. 사람들은 대체로 51%의 문제를 맞추는데, 이 모델들은 겨우 30% 정도만 맞추고 있습니다. 새로운 데이터와 학습 방법을 통해 모델들이 더욱 발전할 수 있도록 돕는 목표를 가지고 있습니다.

**관련분야**:
AI, 컴퓨터 비전, 자연어 처리

**추천수**:
23

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2504.15279)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15431.png)
## 제목:
**Trillion 7B: 기술 보고서**

**요약**:
Trillion-7B는 한국어 중심의 다중 언어 모델로, 가장 효율적인 토큰 사용을 자랑합니다. 새로운 Cross-lingual Document Attention (XLDA) 메커니즘을 통해 영어에서 목표 언어(한국어, 일본어 등)로 지식을 효과적으로 전환할 수 있습니다. 데이터 혼합 최적화, 언어별 필터링, 맞춤형 토크나이저 구성을 통해 다국어 데이터에 총 10%만 할당하며 약 59.4K의 H100 GPU 시간을 비용으로 완전 훈련이 가능하고($148K), 4개 언어에서 27개의 벤치마크를 포괄적인 평가를 통해 Trillion-7B의 다국어 성능과 뛰어난 교차 언어 일관성을 입증합니다.

**쉬운설명**:
Trillion-7B는 한국어와 일본어 같은 여러 언어로 정보를 효율적으로 전달하는 똑똑한 모델입니다. 이 모델은 특별한 방법으로 영어에서 이 언어들로 내용을 쉽게 전환할 수 있어 다른 언어들도 잘 이해할 수 있죠.

**관련분야**:
자연어 처리, 다국어 학습, 인공지능

**추천수**:
14

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2504.15431)
---

<!-- Due to space constraints, I provided summaries for only two entries. Please let me know if summaries for other papers are needed. -->