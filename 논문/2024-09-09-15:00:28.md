
![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.02877.png)
## 제목:
Configurable Foundation Models: Building LLMs from a Modular Perspective

**요약**:

최근 큰 언어 모델(LLM)에서 컴퓨팅 성능과 지속적인 확장성 문제가 대두되고 있습니다. 이는 방대한 매개변수 때문인데, 이로 인해 한정된 계산 자원을 가진 장치에서는 모델의 응용과 발전이 어려워지고 있습니다. 이에 따라 인간 두뇌의 모듈성(Modularity)에 영감을 받아, LLM을 여러 기능 모듈로 분해하려는 경향이 증가하고 있습니다. 이 논문에서는 기능 모듈 또는 '벽돌(brick)'이 각각의 모듈을 나타내고, 이러한 모듈화된 구조를 구성 가능한 기본 모델(configurable foundation models)로 명명합니다.

이 논문은 이러한 구성 가능한 기본 모델의 설계, 활용 및 제한점을 종합적으로 조사합니다. 저자들은 사전 학습 중에 나타나는 기능적 뉴런 구역으로 모듈을 형식화하고, 사후 학습을 통해 추가로 구성된 '커스터마이즈 브릭(customized bricks)'를 제안합니다. 다양한 기능적 브릭을 기반으로 '검색과 라우팅(retrieval and routing)', '병합(merging)', '업데이트(updating)', '성장(growing)'의 네 가지 브릭 지향 작업을 제안합니다. 이를 통해 복잡한 작업을 처리하는 데 필요한 LLM의 동적 구성을 가능하게 합니다.

실증 분석 결과 FFN 레이어가 뉴런의 기능적 특수화 및 기능적 뉴런 구역을 따라 모듈 패턴을 따르는 것을 확인했습니다. 마지막으로, 여러 미해결 문제와 향후 연구 방향을 강조합니다.

**쉬운설명**:

이 논문은 사람들이 더 효율적으로 큰 언어 모델(LLM)을 만들고 사용할 수 있는 새로운 방법에 대해 다룹니다. 모델을 여러 작은 부분(모듈)으로 나누어 필요한 부분만 사용하여 복잡한 문제를 해결할 수 있는 방법을 제안합니다. 이를 통해 더 적은 컴퓨터 자원으로 다양한 작업을 빠르게 수행할 수 있습니다.

**관련분야**: 인공지능(AI), 자연어 처리(NLP), 머신러닝(ML)

**추천수**: 4

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.02877)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03810.png)
## 제목:
How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data

**요약**:

최근 코드 지침 데이터 구축에 대한 관심이 증가하고 있습니다. 그러나 이러한 데이터셋으로 훈련된 코드 모델들이 HumanEval에서는 높은 성능을 보이는 반면, LiveCodeBench에서는 성능이 저하되는 문제점이 발생했습니다. 그 이유를 조사한 결과, 많은 데이터셋에서 데이터 유출이 심각하다는 것을 발견했습니다. 이 문제를 해결하기 위해 우리는 고품질 샘플을 선택하는 효율적인 코드 데이터 가지치기 전략을 제안합니다.

이를 기반으로 LLaMA3에서 미세 조정된 XCoder 모델 패밀리를 제안합니다. 우리의 실험 결과, XCoder는 새로운 최첨단 성능을 달성했으며, 우리의 데이터 전략의 효과를 입증했습니다. 또한 데이터 구성을 종합적으로 분석하여 기존 코드 데이터셋이 구성 방법에 따라 다른 특성을 가지고 있음을 발견했습니다.

**쉬운설명**:

이 논문은 좋은 코드 작성을 위한 데이터의 중요성에 대해 이야기합니다. 코드 학습 모델들이 다양한 문제에서 일관된 성능을 내기 위해 필요한 데이터를 어떻게 선택하고 사용할지에 대한 전략을 제안합니다. 이를 통해 더 적은 데이터로도 높은 성능을 내는 모델, XCoder를 개발했습니다.

**관련분야**: 인공지능(AI), 코드 생성(Code Generation), 데이터 분석(Data Analysis)

**추천수**: 4

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.03810)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.04005.png)
## 제목:
Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task

**요약**:

확산 변환기(diffusion transformers)에서의 글로벌 자가-어텐션 메커니즘은 시각 정보의 반복성과 중복성 때문에 불필요한 계산을 포함합니다. 이를 해결하기 위해, 대리 토큰(proxy token)을 사용하는 Qihoo-T2X 모델이 제안되었습니다. 각 변환기 블록에서 공간-시간 창마다 하나의 토큰을 무작위로 샘플링하여 해당 영역의 대리 토큰(proxy token)으로 삼고, 이 대리 토큰들의 자가-어텐션을 통해 글로벌 시맨틱을 캡쳐합니다. 그런 다음 대리 토큰들을 통해 모든 잠재 토큰에게 교차 어텐션으로 주입합니다.

Qihoo-T2X는 T2I, T2V, T2MV 작업을 위한 다양한 모델로 확장됩니다. 실험 결과, Qihoo-T2X는 이미지 및 비디오 생성 작업에서 경쟁력 있는 성능을 보이면서도 계산 복잡도를 크게 줄였습니다.

**쉬운설명**:

이 논문은 이미지나 비디오를 효율적으로 생성할 수 있는 Qihoo-T2X라는 새로운 모델을 소개합니다. 많은 계산을 필요로 하지 않으면서도 좋은 성능을 낼 수 있도록, 데이터에서 일부 대표 토큰만 사용하여 전체 정보를 이해하는 방법을 설명합니다.

**관련분야**: 인공지능(AI), 컴퓨터 비전(Computer Vision), 데이터 분석(Data Analysis)

**추천수**: 3

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.04005)

---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.04410.png)
## 제목:
Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation

**요약**:

이 논문은 Google의 MAGVIT-v2 토크나이저를 오픈소스로 복제한 Open-MAGVIT2 프로젝트를 소개합니다. 이 모델은 이미지넷(256x256)에서 최첨단 재구성 성능을 달성합니다. 이 논문은 비대칭 토큰 인자 분해를 통해 매우 큰 어휘집을 예측하는 능력을 향상시키고, 더 나은 생성 품질을 위해 "다음 서브 토큰 예측"을 도입합니다.

모든 모델과 코드는 오픈소스로 공개되어, 자가회귀 시각 생성 분야에서 혁신과 창의성을 촉진하기 위해 제공됩니다.

**쉬운설명**:

이 논문은 이미지를 자동으로 생성하는 모델인 Open-MAGVIT2를 누구나 사용할 수 있도록 공개하는 프로젝트를 소개합니다. 이 모델은 최고의 성능을 자랑하며, 더 나은 이미지 생성을 위해 새로운 기술들을 사용했습니다.

**관련분야**: 인공지능(AI), 시각 생성(Visual Generation), 머신러닝(ML)

**추천수**: 2

**PDF 다운로드 링크**: [PDF 다운로드](https://arxiv.org/pdf/2409.04410)

---

