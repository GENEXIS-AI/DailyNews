![Image](https://cdn-avatars.huggingface.co/v1/production/uploads/628f6e5ab90dde28ef57d293/AxNzR2nvrND6Rf3RPkYMk.jpeg)
## 제목:
**Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale**
**요약**:
대형 언어 모델의 사전 훈련은 일반적으로 인간 전문가가 데이터 품질 개선을 위한 휴리스틱을 제작하는 경우가 많습니다. 그러나 이 방법은 개별 예제의 고유한 특성을 효과적으로 다루기에는 유연성이 부족하며, 모든 예제에 맞춤형 규칙을 적용하는 것은 비현실적입니다. 본 논문에서는 0.3B 파라미터와 같은 작은 언어 모델도 인간 전문가와 비슷한 데이터 정제 능력을 보여줄 수 있음을 증명합니다. 여기에서 소개하는 Programming Every Example (ProX) 프레임워크는 데이터 정제를 프로그래밍 작업으로 간주하여 모델이 규모에 맞춘 세부 작업을 생성 및 실행하도록 합니다. 실험 결과에서 ProX가 큐레이트한 데이터로 사전 훈련된 모델들이 원본 데이터나 다른 선택 방법으로 정제된 데이터보다 다양한 다운스트림 벤치마크에서 2% 이상 성능이 우수했음을 보였습니다. 더 나아가 ProX는 도메인 별 지속적 사전 훈련에서도 큰 잠재력을 가지고 있습니다.

**쉬운설명**:
이 논문은 인공지능 모델을 훈련시키기 위해 보다 높은 품질의 데이터를 만드는 새로운 방법에 대해 논의합니다. 기존에는 전문가들이 수많은 규칙을 통해 데이터를 정제했지만, 이 방법은 한계가 있었습니다. 반면, ProX라는 새로운 방법을 통해 각 데이터 예제에 맞춘 세부 작업을 자동으로 수행함으로써 더 나은 데이터를 만들 수 있다는 것을 보여줍니다.

**관련분야**:
AI, Machine Learning, Data Pre-processing

**추천수**:
17

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17115)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17146.png)
## 제목:
**Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models**
**요약**:
최신 다중 모달 모델들 중 많은 부분이 여전히 독점적입니다. 오픈 가중치를 가진 모델들은 좋은 성능을 이루기 위해 독점적인 VLM에서 많은 부분을 차용합니다. 이에 따라, 커뮤니티는 여전히 좋은 성능의 VLM을 처음부터 어떻게 구축할 수 있는지에 대한 기본적인 지식을 놓치고 있습니다. Molmo는 이러한 문제를 해결하고자 하는 새로운 VLM 모델 패밀리로, 전적으로 사람이 수집한 음성 기반 설명을 통해 세세한 이미지 캡션 데이터셋을 구축했습니다. 이 데이터셋은 다양한 사용자 상호작용을 가능하게 하기 위해 다양한 데이터셋을 혼합해 파인 튜닝했습니다. 이 모델은 GPT-4o, Claude 3.5, Gemini 1.5 같은 독점 시스템과의 비교에서 뛰어난 성능을 보여주었으며, 조직들은 자사 모델 가중치와 데이터를 공개할 예정입니다.

**쉬운설명**:
이 논문에서는 고성능 인공지능 모델을 만들기 위해 공개된 새로운 데이터를 사용하여 Molmo라는 모델을 만들었습니다. 이 모델은 사람이 직접 수집한 매우 세세한 설명 데이터를 사용해 학습하였고, 기존의 독점 모델들보다 좋은 성능을 보여줍니다.

**관련분야**:
AI, Multimodal Models, Open Data

**추천수**:
10

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17146)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17145.png)
## 제목:
**DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion**
**요약**:
최근 2D 확산 모델과 점수 증류 샘플링(SDS)을 활용한 텍스트-3D 아바타 생성 방법들이 유망한 결과를 보였습니다. 그러나 고품질 3D 아바타를 생성하여 표현 가능한 애니메이션으로 만드는 일은 여전히 도전 과제입니다. DreamWaltz-G는 텍스트로부터 애니메이션 가능한 3D 아바타 생성을 위한 새로운 학습 프레임워크를 제공합니다. 이 프레임워크의 핵심은 3D 인간 템플릿의 골격 제어를 2D 확산 모델에 통합하여 SDS 감독의 일관성을 강화하고, 고품질 아바타 생성을 가능케 하는 골격 유도 점수 증류와 하이브리드 3D 가우시안 아바타 표현법입니다. 실험 결과, DreamWaltz-G가 기존 방법들보다 시각적 품질과 애니메이션 표현력에서 우수함을 입증했습니다.

**쉬운설명**:
이 논문은 텍스트를 이용해 고품질의 3D 아바타를 만드는 새로운 방법을 소개합니다. DreamWaltz-G라는 이 방법은 사람 모양의 뼈대를 이용해 고품질 아바타를 만들고, 이 아바타를 이용해 더 자연스러운 애니메이션을 가능하게 합니다.

**관련분야**:
3D Modeling, Animation, Text-to-3D Models

**추천수**:
4

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17145)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.16629.png)
## 제목:
**Synchronize Dual Hands for Physics-Based Dexterous Guitar Playing**
**요약**:
본 논문은 두 손의 높은 시간적 정밀도로 제어를 필요로 하는 작업에 대해 물리적으로 시뮬레이션된 손의 능숙한 동작을 합성하기 위한 새로운 접근 방식을 소개합니다. 각 손을 별개의 에이전트로 취급하여 개별 정책을 먼저 훈련 한 후, 중앙 집중 환경에서 잠재 공간 조작을 통해 동기화하여 두 손의 공동 정책으로 작동하도록 합니다. 이를 통해 두 손의 높은 차원의 공동 상태-행동 공간에서 직접 정책 학습을 수행하는 것을 피하고, 전반적인 훈련 효율성을 크게 향상시킵니다. 제안된 접근 방식의 효용성을 기타 연주 작업에서 증명하였으며, 다양한 리듬을 정확하게 연주할 수 있는 가상 기타리스트를 훈련하는데 성공했습니다.

**쉬운설명**:
이 논문은 기타를 치는 가상 캐릭터를 만드는 방법에 대해 설명합니다. 두 손을 각각 따로 훈련시키고, 나중에 합쳐서 동시에 작동하게 하는 방식으로 기타를 잘 치도록 합니다.

**관련분야**:
Robotics, Machine Learning, Simulation

**추천수**:
3

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.16629)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17058.png)
## 제목:
**Degradation-Guided One-Step Image Super-Resolution with Diffusion Priors**
**요약**:
기존의 확산 기반 이미지 초해상도(SR) 방법들은 주로 도메인 모델을 사전학습된 텍스트-이미지 확산 모델로 활용하여 remarkable한 성공을 거두었지만, 만족스러운 결과를 얻기 위해 여러 샘플링 단계를 거쳐야 하며 이는 실제 시나리오에서 효율성을 제한합니다. 본 논문은 새로운 One-Step SR 모델을 소개하여 이러한 효율성 문제를 크게 해결하고자 합니다. 제안된 모델은 낮은 해상도 이미지에서 사전 추정된 열화 정보를 기반으로 모델 파라미터를 조정하는 열화 유도 Low-Rank Adaptation (LoRA) 모듈을 설계하여 데이터 또는 열화 종속적인 SR을 가능하게 합니다.

**쉬운설명**:
이 논문은 낮은 해상도의 이미지를 높은 해상도로 변환하는 새로운 방법에 대해 설명합니다. 기존 방법은 여러 단계를 거쳐야 하는 반면, 새로운 방법은 단 한 단계로 더 빨리 변환할 수 있습니다.

**관련분야**:
Image Processing, Super-Resolution, Machine Learning

**추천수**:
1

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.17058)
---

![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.16666.png)
## 제목:
**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**
**요약**:
본 논문은 단안 비디오에서 전체 신체 대화를 학습하는 동적 신경 방사장(NeRF) 프레임워크를 소개합니다. 이전 연구들은 주로 신체 자세나 얼굴만을 표현했습니다. 하지만 인간은 전체 신체, 손 제스처, 얼굴 표정을 결합하여 의사소통을 합니다. TalkinNeRF는 신체, 얼굴, 손 모듈을 결합하여 최종 결과를 생성하는 통합 NeRF 기반 네트워크를 제안합니다. 다중 ID 표현을 통해 여러 피사체의 동시 훈련, 완전히 새롭고 보지 못한 자세에서도 강력한 애니메이션이 가능합니다. 실험 결과 TalkinNeRF가 미세한 손의 움직임과 얼굴 표정을 표현하는 전체 신체 애니메이션에서 state-of-the-art 성능을 나타냈음을 증명합니다.

**쉬운설명**:
이 논문은 한 사람의 전체 신체 움직임과 대화를 표현할 수 있는 새로운 AI 모델을 소개합니다. 이 모델은 얼굴뿐만 아니라 손과 몸의 움직임을 모두 포함하여 더 자연스러운 인간의 대화를 표현합니다.

**관련분야**:
Computer Graphics, Animation, Neural Networks

**추천수**:
1

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2409.16666)
---