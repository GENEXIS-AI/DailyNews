![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18547.png)

## 제목:
Token-Budget-Aware LLM Reasoning

**요약**:
이 논문은 대규모 언어 모델(LLM)이 다양한 작업에서 뛰어난 성과를 발휘하기 위해 필요한 '추론'에 초점을 맞추고 있습니다. Chain-of-Thought (CoT) 추론 방법은 문제를 중간 단계로 분해하여 LLM의 성능을 향상시킬 수 있지만, 그 과정에서 많은 토큰이 사용되어 비용이 증가한다는 문제가 있습니다. 저자는 현재 LLM의 추론 과정이 불필요하게 길어질 수 있으며, 적절한 토큰 예산(token budget)을 프롬프트에 포함시켜 이를 압축할 수 있다고 주장합니다. 이 과정에서 토큰 예산의 선택이 실제 압축 효과에 핵심적인 역할을 한다고 밝히고 있습니다. 논문에서는 토큰 예산을 합리적으로 추정하고 다양한 문제에 대해 이를 적용하여 추론 과정의 효율성을 높이는 '토큰-예산-인식 LLM 추론 프레임워크'를 제안합니다. 실험 결과, 제안된 방법이 CoT 추론에서 토큰 비용을 효과적으로 줄이면서 성능 저하는 미비함을 보여주며, 효율성과 정확성 사이의 균형을 맞출 수 있는 실용적인 해결책을 제공합니다.

**쉬운설명**:
이 연구는 인공지능이 문제를 해결할 때 쓰는 방법 중 하나인 '이유를 설명하는 과정'이 시간과 비용을 많이 요구한다는 점에 착안하여, 이를 더 효율적으로 만들기 위한 방법을 찾아봤습니다. 그래서 주어진 문제의 복잡성에 따라 적절한 '토큰 사용량'을 정하고 이를 활용해 이유를 설명하는 과정을 최적화하는 방법을 제안했습니다. 이 방식은 비용을 줄이면서도 성능을 크게 해치지 않는 결과를 보였습니다.

**관련분야**:
인공지능, 자연어 처리, 머신러닝

**추천수**:
3

**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2412.18547)
