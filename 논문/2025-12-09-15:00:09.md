![Image](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.07525.png)
## 제목:
**Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs**
**요약**: 이 논문은 Rotary Position Embeddings를 강화하는 방법을 제안하는데, 복소수 내적의 실수 및 허수 부분을 사용하여 대형 언어 모델에서 긴 문맥 모델링을 개선합니다.
**쉬운설명**: Rotary Position Embeddings(쉬운 말로 말하자면 위치 코드)를 더 발전시키기 위해 상상 속의 숫자(복소수)를 사용하여 문장이 길어도 더 똑똑하게 이해하도록 만든 것이에요.
**관련분야**: 대형 언어 모델, 자연어 처리, 복소수
**추천수**: 21
**PDF 다운로드 링크**: ![PDF 다운로드](https://arxiv.org/pdf/2512.07525)
---